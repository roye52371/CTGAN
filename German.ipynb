{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import Counter\n",
    "import IPython\n",
    "from IPython.core.display import display\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODELS_PATH = './models'\n",
    "dataset = 'german'\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Load data, preprocess, and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, le = read_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 24)\n",
      "(200, 24)\n",
      "(800,)\n",
      "(200,)\n",
      "model score: 0.770\n"
     ]
    }
   ],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "categorical_features=[]\n",
    "preprocessor = get_preprocessor(X, categorical_features)\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', rf)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#keep train alone and test alone for create excel file in code\n",
    "#further in the code\n",
    "X_train_data = X_train\n",
    "X_test_data = X_test\n",
    "y_train_data = y_train\n",
    "y_test_data= y_test\n",
    "# will used it after/before training\n",
    "\n",
    "#print(X_train_data[0])\n",
    "\n",
    "#X_train_data\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Plot confidence scores for all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf_train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#putted in comment the line below, so X_train will not be the whole data\n",
    "#X_train, y_train = X, y\n",
    "#clf.fit(X_train, y_train)\n",
    "#the comment above was allready calc one cell before\n",
    "y_prob = rf.predict_proba(X_train)\n",
    "y_conf_train = y_prob[:, 0]  # confidence scores\n",
    "print(\"y_conf_train\\n\")\n",
    "#print(y_conf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "0\n",
    "plot_confidence_levels(y_conf_train, \"Confidence scores for X_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Select C as the middle of top intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6   3  11  10  96 159 234 224  55   2]\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "# Create bucket (intervals) from generated data\n",
    "top_c = 10\n",
    "conf_bucktes = pd.value_counts(y_conf_train, bins=10, sort=False)\n",
    "idxs, freqs = conf_bucktes.index, conf_bucktes.values\n",
    "#print(idxs[0])\n",
    "akaka=idxs.contains(0.6)\n",
    "print(freqs)\n",
    "freqsSum = freqs.sum()\n",
    "print(freqsSum)\n",
    "\n",
    "\n",
    "# extract top_c intervals by frequency values\n",
    "intervals_idxs = np.argsort(freqs)[::-1][:top_c]\n",
    "top_c_intervals = idxs[intervals_idxs]\n",
    "\n",
    "# create top_c_lst as the middle of the interval\n",
    "top_c_lst = [(interval.right + interval.left)/2 for interval in top_c_intervals]\n",
    "top_c_lst = sorted(round(x, 4) for x in top_c_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.484, 0.5135, 0.5425, 0.5715, 0.6005, 0.6295, 0.6585, 0.6875, 0.7165, 0.7455]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_c_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Train one CTGAN with middle of intervals (10 Confidence levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of epochs\n",
      "\n",
      "50\n",
      "Training CTGAN for c list = [0.484, 0.5135, 0.5425, 0.5715, 0.6005, 0.6295, 0.6585, 0.6875, 0.7165, 0.7455] ...\n",
      "\tGenerate samples to same dist...\n",
      "[[0.75 0.25]\n",
      " [0.82 0.18]\n",
      " [0.82 0.18]\n",
      " ...\n",
      " [0.77 0.23]\n",
      " [0.75 0.25]\n",
      " [0.78 0.22]]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 6\n",
      "\n",
      "index 1 values left 3\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 9/800\n",
      "\n",
      "ans\n",
      "\n",
      "(791,)\n",
      "train_ans\n",
      "\n",
      "(791,)\n",
      "gen_data\n",
      "(791, 24)\n",
      "relevant_X_train\n",
      "(791, 24)\n",
      "y_conf_gen\n",
      "(791,)\n",
      "relevant_y_conf_train\n",
      "(791,)\n",
      "\tWorking on results...\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "datagen inv size:\n",
      "18984\n",
      "\n",
      "\n",
      "current bin size:\n",
      "6\n",
      "\n",
      "\n",
      "\tResults for confidence level = 0.484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>37.2946 | 100.0</td>\n",
       "      <td>38.9381 | 100.0</td>\n",
       "      <td>39.3173 | 100.0</td>\n",
       "      <td>39.3173 | 100.0</td>\n",
       "      <td>39.3173 | 100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.01             0.05             0.10             0.15  \\\n",
       "0.80    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0   \n",
       "0.85    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0   \n",
       "0.90   99.115 | 100.0   99.115 | 100.0   99.115 | 100.0   99.115 | 100.0   \n",
       "0.95  88.4956 | 100.0  88.4956 | 100.0   88.622 | 100.0   88.622 | 100.0   \n",
       "0.99  37.2946 | 100.0  38.9381 | 100.0  39.3173 | 100.0  39.3173 | 100.0   \n",
       "\n",
       "                 0.20  \n",
       "0.80    100.0 | 100.0  \n",
       "0.85    100.0 | 100.0  \n",
       "0.90   99.115 | 100.0  \n",
       "0.95   88.622 | 100.0  \n",
       "0.99  39.3173 | 100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerate samples to same dist...\n",
      "[[0.82 0.18]\n",
      " [0.8  0.2 ]\n",
      " [0.74 0.26]\n",
      " ...\n",
      " [0.86 0.14]\n",
      " [0.63 0.37]\n",
      " [0.56 0.44]]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 6\n",
      "\n",
      "index 1 values left 3\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 9/800\n",
      "\n",
      "ans\n",
      "\n",
      "(791,)\n",
      "train_ans\n",
      "\n",
      "(791,)\n",
      "gen_data\n",
      "(791, 24)\n",
      "relevant_X_train\n",
      "(791, 24)\n",
      "y_conf_gen\n",
      "(791,)\n",
      "relevant_y_conf_train\n",
      "(791,)\n",
      "\tWorking on results...\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "datagen inv size:\n",
      "18984\n",
      "\n",
      "\n",
      "current bin size:\n",
      "3\n",
      "\n",
      "\n",
      "\tResults for confidence level = 0.5135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>88.2427 | 100.0</td>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>38.0531 | 100.0</td>\n",
       "      <td>38.9381 | 100.0</td>\n",
       "      <td>39.1909 | 100.0</td>\n",
       "      <td>39.1909 | 100.0</td>\n",
       "      <td>39.1909 | 100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0.01             0.05             0.10             0.15  \\\n",
       "0.80    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0   \n",
       "0.85    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0   \n",
       "0.90   99.115 | 100.0   99.115 | 100.0   99.115 | 100.0   99.115 | 100.0   \n",
       "0.95  88.2427 | 100.0  88.4956 | 100.0  88.4956 | 100.0  88.4956 | 100.0   \n",
       "0.99  38.0531 | 100.0  38.9381 | 100.0  39.1909 | 100.0  39.1909 | 100.0   \n",
       "\n",
       "                 0.20  \n",
       "0.80    100.0 | 100.0  \n",
       "0.85    100.0 | 100.0  \n",
       "0.90   99.115 | 100.0  \n",
       "0.95  88.4956 | 100.0  \n",
       "0.99  39.1909 | 100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerate samples to same dist...\n",
      "[[0.82 0.18]\n",
      " [0.76 0.24]\n",
      " [0.66 0.34]\n",
      " ...\n",
      " [0.82 0.18]\n",
      " [0.73 0.27]\n",
      " [0.74 0.26]]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 6\n",
      "\n",
      "index 1 values left 3\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 9/800\n",
      "\n",
      "ans\n",
      "\n",
      "(791,)\n",
      "train_ans\n",
      "\n",
      "(791,)\n",
      "gen_data\n",
      "(791, 24)\n",
      "relevant_X_train\n",
      "(791, 24)\n",
      "y_conf_gen\n",
      "(791,)\n",
      "relevant_y_conf_train\n",
      "(791,)\n",
      "\tWorking on results...\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.8 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.85 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.9 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.95 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.01\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.05\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.1\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.15\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "calc for sim_threshold= 0.99 and conf_diff_threshold=0.2\n",
      "enter coverage function\n",
      "\n",
      "exit coversge function\n",
      "\n",
      "enter precision function\n",
      "\n",
      "exit precision function\n",
      "\n",
      "datagen inv size:\n",
      "18984\n",
      "\n",
      "\n",
      "current bin size:\n",
      "11\n",
      "\n",
      "\n",
      "\tResults for confidence level = 0.5425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.10</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "      <td>100.0 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "      <td>99.115 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>88.4956 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "      <td>88.622 | 100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>37.8003 | 98.3565</td>\n",
       "      <td>39.0645 | 100.0</td>\n",
       "      <td>39.1909 | 100.0</td>\n",
       "      <td>39.1909 | 100.0</td>\n",
       "      <td>39.1909 | 100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0.01             0.05             0.10             0.15  \\\n",
       "0.80      100.0 | 100.0    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0   \n",
       "0.85      100.0 | 100.0    100.0 | 100.0    100.0 | 100.0    100.0 | 100.0   \n",
       "0.90     99.115 | 100.0   99.115 | 100.0   99.115 | 100.0   99.115 | 100.0   \n",
       "0.95    88.4956 | 100.0   88.622 | 100.0   88.622 | 100.0   88.622 | 100.0   \n",
       "0.99  37.8003 | 98.3565  39.0645 | 100.0  39.1909 | 100.0  39.1909 | 100.0   \n",
       "\n",
       "                 0.20  \n",
       "0.80    100.0 | 100.0  \n",
       "0.85    100.0 | 100.0  \n",
       "0.90   99.115 | 100.0  \n",
       "0.95   88.622 | 100.0  \n",
       "0.99  39.1909 | 100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGenerate samples to same dist...\n",
      "[[0.67 0.33]\n",
      " [0.75 0.25]\n",
      " [0.81 0.19]\n",
      " ...\n",
      " [0.77 0.23]\n",
      " [0.78 0.22]\n",
      " [0.79 0.21]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-910409b3990e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;31m#print(train_bucktes_gen)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[1;31m# ans is the indices of gen_data to make the same dist\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m     \u001B[0mans\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_ans\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen_data_to_same_conf_dist_as_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_conf_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_conf_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[0mgen_data_same_dist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mans\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[0my_conf_gen_same_dist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my_conf_gen\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mans\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\git_CTGAN_project_directory\\CTGAN\\utils.py\u001B[0m in \u001B[0;36mgen_data_to_same_conf_dist_as_train\u001B[1;34m(y_conf_gen, y_conf_train)\u001B[0m\n\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m         \u001B[1;31m# find interval index which contains the sample_conf (-1 if not found)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 248\u001B[1;33m         \u001B[0minterval_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0midxs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontains\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_conf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    249\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    250\u001B[0m         \u001B[1;31m# value not fould (empty list of indices)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\roi52\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\extension.py\u001B[0m in \u001B[0;36mmethod\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 78\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     79\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mwrap\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\roi52\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\arrays\\interval.py\u001B[0m in \u001B[0;36mcontains\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m   1241\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1242\u001B[0m         return (self.left < other if self.open_left else self.left <= other) & (\n\u001B[1;32m-> 1243\u001B[1;33m             \u001B[0mother\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mright\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen_right\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mother\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mright\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1244\u001B[0m         )\n\u001B[0;32m   1245\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\roi52\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mcmp_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merrstate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcomparison_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_bool_dtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\n",
    "# X_train = X_all\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# train CTGAN\n",
    "z_features = get_noise_features(X_train, categorical_features)\n",
    "z_rows = int(0.25 * X_train.shape[0])\n",
    "z = gen_random_noise(shape=(z_rows, z_features))\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "#epochs = 100\n",
    "print(\"num of epochs\\n\")\n",
    "print(epochs)\n",
    "#confidence_level = c\n",
    "gen_lr = 2e-5\n",
    "loss = 'log'\n",
    "\n",
    "#now ctgan synthesizer gets conf levels as input\n",
    "rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n",
    "                            blackbox_model=rf,\n",
    "                            preprocessing_pipeline=preprocessor,\n",
    "                            bb_loss=loss,\n",
    "                            confidence_levels=top_c_lst\n",
    "                            )\n",
    "#print(rf_ctgan.confidence_levels)\n",
    "\n",
    "print(f\"Training CTGAN for c list = {top_c_lst} ...\")\n",
    "#removed conf level from fit input arguements\n",
    "allconf_levels_hist = rf_ctgan.fit(train_data=z,\n",
    "                                   epochs=epochs,\n",
    "                                   gen_lr=gen_lr,\n",
    "                                   verbose=False\n",
    "                                  )\n",
    "\n",
    "#print(\"\\nhistory of all confidence levels:\\n\")\n",
    "#print(allconf_levels_hist)\n",
    "#print(\"\\n\\n\")\n",
    "# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\n",
    "# plot_losses(hist, title=f'{dataset} loss, c = {confidence_level}')\n",
    "# print()\n",
    "\n",
    "#allsamplesInv = 0\n",
    "#allDataFrames = []\n",
    "#allgeninv= 0\n",
    "alldataframescoverage =[]\n",
    "alldataframesprecision =[]\n",
    "freqsCounter = 0\n",
    "#add here conf loop, send each conf to samples as input each loop\n",
    "for c in top_c_lst:\n",
    "    print(\"\\tGenerate samples to same dist...\")\n",
    "    # Generate samples to same dist\n",
    "    samples = 100000\n",
    "    #samples = 200000\n",
    "    gen_data,gen_fakeacts = rf_ctgan.sample(samples,c)\n",
    "    y_prob = rf.predict_proba(gen_data)\n",
    "    print(y_prob)\n",
    "    y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "    #print(y_conf_gen)\n",
    "    #print(y_conf_train)\n",
    "\n",
    "    #train_bucktes_gen = pd.value_counts(y_conf_gen, bins=10, sort=False)\n",
    "    #print(train_bucktes_gen)\n",
    "    # ans is the indices of gen_data to make the same dist\n",
    "    ans,train_ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "    gen_data_same_dist = gen_data.iloc[ans]\n",
    "    y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\n",
    "    #take only relevant sample from train\n",
    "    relevant_train_data = X_train_pd.iloc[train_ans]\n",
    "    relevant_y_conf_train = y_conf_train[train_ans]\n",
    "\n",
    "\n",
    "\n",
    "    # inverse the generated data\n",
    "    scaler = get_scaler(preprocessor)\n",
    "    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "    gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "\n",
    "    #calc all inv\n",
    "    #freqs[freqsCounter] probably in our the gen size data train\n",
    "    # in the interval bin that c in it\n",
    "    #allgeninv = allgeninv + freqs[freqsCounter]\n",
    "    #calc end\n",
    "\n",
    "    # y_conf_gen_same_dist, gen_data_inv what we want\n",
    "    # results\n",
    "    # E. Calculate coverage for each similarity and conf diff thresholds\n",
    "\n",
    "    #sum all geninvsamples\n",
    "    #allsamplesInv =allsamplesInv + gen_data_inv.size()\n",
    "\n",
    "    print(\"gen_data\")\n",
    "    print(gen_data_inv.shape)\n",
    "    print(\"relevant_X_train\")\n",
    "    print(relevant_train_data.shape)\n",
    "    print(\"y_conf_gen\")\n",
    "    print(y_conf_gen_same_dist.shape)\n",
    "    print(\"relevant_y_conf_train\")\n",
    "    print(relevant_y_conf_train.shape)\n",
    "\n",
    "\n",
    "    print(f\"\\tWorking on results...\")\n",
    "    results,coverage, precision = table(gen_data_inv, relevant_train_data, y_conf_gen_same_dist, relevant_y_conf_train)\n",
    "\n",
    "    print(\"datagen inv size:\")\n",
    "    print(gen_data_inv.size)\n",
    "    print(\"\\n\")\n",
    "    print(\"current bin size:\")\n",
    "    print(freqs[freqsCounter])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #keep all data frames\n",
    "    alldataframescoverage.append([coverage,freqs[freqsCounter]])\n",
    "    alldataframesprecision.append([precision,freqs[freqsCounter]])\n",
    "   # allDataFrames.append(results)\n",
    "\n",
    "    print(f\"\\tResults for confidence level = {c}\")\n",
    "    display(results)\n",
    "    freqsCounter=freqsCounter+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"allgen in size\")\n",
    "#print(allgeninv)\n",
    "#print(\"\\n\")\n",
    "print(\"all bins size\")\n",
    "print(freqsSum)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"calculate weighted average results\\n\")\n",
    "a= alldataframescoverage[0][0] *0\n",
    "#display(a)\n",
    "for index in range(len(alldataframescoverage)):\n",
    "    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\n",
    "    a= a+ alldataframescoverage[index][0]*alldataframescoverage[index][1]\n",
    "a = a/freqsSum\n",
    "#display weighted averaged coverage\n",
    "display(a)\n",
    "\n",
    "\n",
    "b= alldataframesprecision[0][0] *0\n",
    "#display(b)\n",
    "for index in range(len(alldataframesprecision)):\n",
    "    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\n",
    "    b= b+ alldataframesprecision[index][0]*alldataframesprecision[index][1]\n",
    "b = b/freqsSum\n",
    "#display weighted averaged precision\n",
    "display(b)\n",
    "\n",
    "a = a.astype(str)\n",
    "b = b.astype(str)\n",
    "\n",
    "result_weighted_Average = a+\" | \"+b\n",
    "\n",
    "print(\"result_weighted_Average:\\n\")\n",
    "display(result_weighted_Average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. Train and Test centroid and cosine similatry Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf_train_data\n",
      "\n",
      "y_conf_test_data\n",
      "\n",
      "Training CTGAN for c list = [0.602, 0.6275, 0.6525, 0.6775, 0.7025, 0.7275, 0.7525, 0.7775, 0.8025, 0.8275] ...\n",
      "\n",
      "losses history of all confidence levels:\n",
      "\n",
      "{'confidence_levels_history': [{'confidence_level': 0.602, 'loss_g': [0.7104061245918274, 0.7385865449905396, 0.7515325546264648, 0.7390775084495544, 0.7373513579368591, 0.7072733640670776, 0.7238169312477112, 0.7278516888618469, 0.7052707672119141, 0.7455285787582397, 0.7177296280860901, 0.7295937538146973, 0.7245894074440002, 0.7195314168930054, 0.7354074120521545, 0.7229735851287842, 0.7380052804946899, 0.7296624183654785, 0.7483260631561279, 0.7245435118675232, 0.7231214046478271, 0.7096056938171387, 0.7295220494270325, 0.709946870803833, 0.7267011404037476, 0.7394911050796509, 0.7397049069404602, 0.7213873267173767, 0.7325066924095154, 0.7325631976127625, 0.7188715934753418, 0.721291184425354, 0.7470902800559998, 0.7345044016838074, 0.765540599822998, 0.7172146439552307, 0.7318322062492371, 0.7360321283340454, 0.7146987915039062, 0.7309462428092957, 0.7274225354194641, 0.7212410569190979, 0.7182718515396118, 0.7236554622650146, 0.7219445109367371, 0.7246957421302795, 0.7377753257751465, 0.7390635013580322, 0.7368488311767578, 0.7428004145622253, 0.7290676832199097, 0.7186980843544006, 0.7281563878059387, 0.7378833889961243, 0.7258226275444031, 0.7424261569976807, 0.7231011986732483, 0.7203629612922668, 0.7469202876091003, 0.722582995891571, 0.7291618585586548, 0.7279998660087585, 0.7233990430831909, 0.7206358909606934, 0.73790442943573, 0.7346146702766418, 0.7204956412315369, 0.7235659956932068, 0.7379875779151917, 0.7321581244468689, 0.728084921836853, 0.7280218005180359, 0.7287616729736328, 0.719280481338501, 0.7298588156700134, 0.7308268547058105, 0.731477677822113, 0.7462754249572754, 0.7477796077728271, 0.7468432188034058, 0.732915997505188, 0.7378404140472412, 0.7367063164710999, 0.7308408617973328, 0.728317141532898, 0.7405332922935486, 0.7371933460235596, 0.747523844242096, 0.7222816348075867, 0.7407515048980713, 0.7298153638839722, 0.7289822101593018, 0.7467955946922302, 0.7338641881942749, 0.7350113987922668, 0.7328177690505981, 0.7352510690689087, 0.7142355442047119, 0.7236335277557373, 0.7269080877304077], 'loss_bb': [0.7104061245918274, 0.7385865449905396, 0.7515325546264648, 0.7390775084495544, 0.7373513579368591, 0.7072733640670776, 0.7238169312477112, 0.7278516888618469, 0.7052707672119141, 0.7455285787582397, 0.7177296280860901, 0.7295937538146973, 0.7245894074440002, 0.7195314168930054, 0.7354074120521545, 0.7229735851287842, 0.7380052804946899, 0.7296624183654785, 0.7483260631561279, 0.7245435118675232, 0.7231214046478271, 0.7096056938171387, 0.7295220494270325, 0.709946870803833, 0.7267011404037476, 0.7394911050796509, 0.7397049069404602, 0.7213873267173767, 0.7325066924095154, 0.7325631976127625, 0.7188715934753418, 0.721291184425354, 0.7470902800559998, 0.7345044016838074, 0.765540599822998, 0.7172146439552307, 0.7318322062492371, 0.7360321283340454, 0.7146987915039062, 0.7309462428092957, 0.7274225354194641, 0.7212410569190979, 0.7182718515396118, 0.7236554622650146, 0.7219445109367371, 0.7246957421302795, 0.7377753257751465, 0.7390635013580322, 0.7368488311767578, 0.7428004145622253, 0.7290676832199097, 0.7186980843544006, 0.7281563878059387, 0.7378833889961243, 0.7258226275444031, 0.7424261569976807, 0.7231011986732483, 0.7203629612922668, 0.7469202876091003, 0.722582995891571, 0.7291618585586548, 0.7279998660087585, 0.7233990430831909, 0.7206358909606934, 0.73790442943573, 0.7346146702766418, 0.7204956412315369, 0.7235659956932068, 0.7379875779151917, 0.7321581244468689, 0.728084921836853, 0.7280218005180359, 0.7287616729736328, 0.719280481338501, 0.7298588156700134, 0.7308268547058105, 0.731477677822113, 0.7462754249572754, 0.7477796077728271, 0.7468432188034058, 0.732915997505188, 0.7378404140472412, 0.7367063164710999, 0.7308408617973328, 0.728317141532898, 0.7405332922935486, 0.7371933460235596, 0.747523844242096, 0.7222816348075867, 0.7407515048980713, 0.7298153638839722, 0.7289822101593018, 0.7467955946922302, 0.7338641881942749, 0.7350113987922668, 0.7328177690505981, 0.7352510690689087, 0.7142355442047119, 0.7236335277557373, 0.7269080877304077]}, {'confidence_level': 0.6275, 'loss_g': [0.7038354277610779, 0.7221986651420593, 0.7112717032432556, 0.7134339809417725, 0.7396101951599121, 0.7248253226280212, 0.7044907808303833, 0.7287775874137878, 0.7244359850883484, 0.7137675285339355, 0.732001781463623, 0.7155514359474182, 0.6984097957611084, 0.7035012245178223, 0.7084195613861084, 0.7133638262748718, 0.7207607626914978, 0.7319437861442566, 0.7308968901634216, 1.4624006748199463, 0.7002347707748413, 0.7326826453208923, 0.716056227684021, 0.71965491771698, 0.71555095911026, 0.7107817530632019, 0.7046335935592651, 0.7244815826416016, 0.7145565152168274, 0.7341604828834534, 0.704293429851532, 0.7180919647216797, 0.6989280581474304, 0.7187376022338867, 0.7113043069839478, 0.7193639874458313, 0.7128757834434509, 0.7218930125236511, 0.721390426158905, 0.7092873454093933, 0.7261062860488892, 0.7293177843093872, 0.7333834171295166, 0.7143344283103943, 0.7250667214393616, 0.7086856961250305, 0.7181248068809509, 0.7113555669784546, 0.7512125968933105, 0.7064728140830994, 0.6944029331207275, 0.7156727313995361, 0.7104434370994568, 0.707385778427124, 0.7180237174034119, 0.7143012881278992, 0.7135669589042664, 0.7055457830429077, 0.710044801235199, 0.7259625196456909, 0.724823534488678, 0.7277082800865173, 0.7219086289405823, 0.7258786559104919, 0.7092724442481995, 0.7374058365821838, 0.7316611409187317, 0.7094046473503113, 0.703093409538269, 0.7384176850318909, 0.714766263961792, 0.718718945980072, 0.7196536064147949, 0.7230758666992188, 0.7323293089866638, 0.7150881886482239, 0.7084407210350037, 0.7158764600753784, 0.707648515701294, 0.7189421057701111, 0.7156710624694824, 0.7492165565490723, 0.7203001379966736, 0.7281569242477417, 0.7284737825393677, 0.7176424264907837, 0.7174535393714905, 0.7067968249320984, 0.709936261177063, 0.716683566570282, 0.7084252238273621, 0.7297852635383606, 0.7193101644515991, 0.7212427258491516, 0.7151304483413696, 0.7399513721466064, 0.709149956703186, 0.7182578444480896, 0.7188223600387573, 0.7248291373252869], 'loss_bb': [0.7038354277610779, 0.7221986651420593, 0.7112717032432556, 0.7134339809417725, 0.7396101951599121, 0.7248253226280212, 0.7044907808303833, 0.7287775874137878, 0.7244359850883484, 0.7137675285339355, 0.732001781463623, 0.7155514359474182, 0.6984097957611084, 0.7035012245178223, 0.7084195613861084, 0.7133638262748718, 0.7207607626914978, 0.7319437861442566, 0.7308968901634216, 1.4624006748199463, 0.7002347707748413, 0.7326826453208923, 0.716056227684021, 0.71965491771698, 0.71555095911026, 0.7107817530632019, 0.7046335935592651, 0.7244815826416016, 0.7145565152168274, 0.7341604828834534, 0.704293429851532, 0.7180919647216797, 0.6989280581474304, 0.7187376022338867, 0.7113043069839478, 0.7193639874458313, 0.7128757834434509, 0.7218930125236511, 0.721390426158905, 0.7092873454093933, 0.7261062860488892, 0.7293177843093872, 0.7333834171295166, 0.7143344283103943, 0.7250667214393616, 0.7086856961250305, 0.7181248068809509, 0.7113555669784546, 0.7512125968933105, 0.7064728140830994, 0.6944029331207275, 0.7156727313995361, 0.7104434370994568, 0.707385778427124, 0.7180237174034119, 0.7143012881278992, 0.7135669589042664, 0.7055457830429077, 0.710044801235199, 0.7259625196456909, 0.724823534488678, 0.7277082800865173, 0.7219086289405823, 0.7258786559104919, 0.7092724442481995, 0.7374058365821838, 0.7316611409187317, 0.7094046473503113, 0.703093409538269, 0.7384176850318909, 0.714766263961792, 0.718718945980072, 0.7196536064147949, 0.7230758666992188, 0.7323293089866638, 0.7150881886482239, 0.7084407210350037, 0.7158764600753784, 0.707648515701294, 0.7189421057701111, 0.7156710624694824, 0.7492165565490723, 0.7203001379966736, 0.7281569242477417, 0.7284737825393677, 0.7176424264907837, 0.7174535393714905, 0.7067968249320984, 0.709936261177063, 0.716683566570282, 0.7084252238273621, 0.7297852635383606, 0.7193101644515991, 0.7212427258491516, 0.7151304483413696, 0.7399513721466064, 0.709149956703186, 0.7182578444480896, 0.7188223600387573, 0.7248291373252869]}, {'confidence_level': 0.6525, 'loss_g': [0.7154276967048645, 0.6955400705337524, 0.6975255608558655, 0.6868757605552673, 0.7134978771209717, 0.7001317739486694, 0.6931565999984741, 0.6947795748710632, 0.7084754109382629, 0.695769190788269, 0.6994032859802246, 0.684217095375061, 0.7073284387588501, 0.7012789249420166, 0.6964860558509827, 0.7067223191261292, 0.6969379782676697, 0.6924422979354858, 0.709807276725769, 0.6941551566123962, 0.7141936421394348, 0.6938295364379883, 0.7003018260002136, 0.7136515974998474, 0.6970939636230469, 0.6941595077514648, 0.6900323629379272, 0.6860482096672058, 0.7014025449752808, 0.6991437077522278, 0.6966712474822998, 0.7006745338439941, 0.6939511299133301, 0.7081949710845947, 0.6912715435028076, 0.6935225129127502, 0.7114774584770203, 0.7082527875900269, 0.688707709312439, 0.7113593816757202, 0.7026022672653198, 0.6877778172492981, 0.7011058330535889, 0.7222482562065125, 0.7109853029251099, 0.7026755809783936, 0.6965559720993042, 0.6989896893501282, 0.6916449069976807, 0.7108466029167175, 0.6909435391426086, 0.7140171527862549, 0.7293487191200256, 0.6969215869903564, 0.702704668045044, 0.7122259736061096, 0.7271839380264282, 0.7212884426116943, 0.716099739074707, 0.7037623524665833, 0.7050787806510925, 0.7153350114822388, 0.7183336019515991, 0.6992770433425903, 0.7098905444145203, 0.7090134620666504, 0.7092103958129883, 0.7196865677833557, 0.720823347568512, 0.7067732214927673, 0.6982749700546265, 0.6973043084144592, 0.7139353156089783, 0.6993750929832458, 0.7004414796829224, 0.7134870886802673, 0.7224061489105225, 0.7091314792633057, 0.7227798104286194, 0.714124858379364, 0.7238033413887024, 0.7214952111244202, 0.7085872292518616, 0.7156069874763489, 0.7402829527854919, 0.7273955345153809, 0.7296901941299438, 0.7232332825660706, 0.7320459485054016, 0.7287328839302063, 0.7330527305603027, 0.7366950511932373, 0.7323454022407532, 0.72699373960495, 0.7373754382133484, 0.7230527400970459, 0.7311550974845886, 0.7376736998558044, 0.7344832420349121, 0.7215030789375305], 'loss_bb': [0.7154276967048645, 0.6955400705337524, 0.6975255608558655, 0.6868757605552673, 0.7134978771209717, 0.7001317739486694, 0.6931565999984741, 0.6947795748710632, 0.7084754109382629, 0.695769190788269, 0.6994032859802246, 0.684217095375061, 0.7073284387588501, 0.7012789249420166, 0.6964860558509827, 0.7067223191261292, 0.6969379782676697, 0.6924422979354858, 0.709807276725769, 0.6941551566123962, 0.7141936421394348, 0.6938295364379883, 0.7003018260002136, 0.7136515974998474, 0.6970939636230469, 0.6941595077514648, 0.6900323629379272, 0.6860482096672058, 0.7014025449752808, 0.6991437077522278, 0.6966712474822998, 0.7006745338439941, 0.6939511299133301, 0.7081949710845947, 0.6912715435028076, 0.6935225129127502, 0.7114774584770203, 0.7082527875900269, 0.688707709312439, 0.7113593816757202, 0.7026022672653198, 0.6877778172492981, 0.7011058330535889, 0.7222482562065125, 0.7109853029251099, 0.7026755809783936, 0.6965559720993042, 0.6989896893501282, 0.6916449069976807, 0.7108466029167175, 0.6909435391426086, 0.7140171527862549, 0.7293487191200256, 0.6969215869903564, 0.702704668045044, 0.7122259736061096, 0.7271839380264282, 0.7212884426116943, 0.716099739074707, 0.7037623524665833, 0.7050787806510925, 0.7153350114822388, 0.7183336019515991, 0.6992770433425903, 0.7098905444145203, 0.7090134620666504, 0.7092103958129883, 0.7196865677833557, 0.720823347568512, 0.7067732214927673, 0.6982749700546265, 0.6973043084144592, 0.7139353156089783, 0.6993750929832458, 0.7004414796829224, 0.7134870886802673, 0.7224061489105225, 0.7091314792633057, 0.7227798104286194, 0.714124858379364, 0.7238033413887024, 0.7214952111244202, 0.7085872292518616, 0.7156069874763489, 0.7402829527854919, 0.7273955345153809, 0.7296901941299438, 0.7232332825660706, 0.7320459485054016, 0.7287328839302063, 0.7330527305603027, 0.7366950511932373, 0.7323454022407532, 0.72699373960495, 0.7373754382133484, 0.7230527400970459, 0.7311550974845886, 0.7376736998558044, 0.7344832420349121, 0.7215030789375305]}, {'confidence_level': 0.6775, 'loss_g': [0.687287449836731, 0.6873742341995239, 0.6975448131561279, 0.6926442384719849, 0.6971704959869385, 0.7083390951156616, 0.6987299919128418, 0.6938727498054504, 0.6891064047813416, 0.710136890411377, 0.6965637803077698, 0.7038024663925171, 0.7081465721130371, 0.7059897184371948, 0.6908268928527832, 0.6910354495048523, 0.6940746903419495, 0.7100236415863037, 0.6974671483039856, 0.7032625675201416, 0.7089315056800842, 0.7017815709114075, 0.7047857642173767, 0.7097731232643127, 0.7108651399612427, 0.7083536386489868, 0.714970588684082, 0.714926540851593, 0.7139217853546143, 0.6924275755882263, 0.7164666056632996, 0.7139139771461487, 0.7146806716918945, 0.7034685015678406, 0.7186117172241211, 0.7089993357658386, 0.7151094675064087, 0.7081248164176941, 0.7115813493728638, 0.7068505883216858, 0.7057949304580688, 0.7057104110717773, 0.7187182903289795, 0.7242244482040405, 0.7158671617507935, 0.7174245119094849, 0.695327639579773, 0.7174078822135925, 0.7038179636001587, 0.7237193584442139, 0.7309595942497253, 0.7095659971237183, 0.7086156010627747, 0.7244348526000977, 0.7241399884223938, 0.7250968813896179, 0.7098488807678223, 0.7193167805671692, 0.7222005128860474, 0.7371746301651001, 0.7135050296783447, 0.710416853427887, 0.724004328250885, 0.699338436126709, 0.732175886631012, 0.7201754450798035, 0.7150835394859314, 0.7242631912231445, 0.7300018072128296, 0.7088702917098999, 0.7195713520050049, 0.7241129875183105, 0.7210251092910767, 0.7180167436599731, 0.7100347280502319, 0.7187146544456482, 0.7243160605430603, 0.7300400733947754, 0.7434679269790649, 0.7227144837379456, 0.7273004651069641, 0.7364815473556519, 0.7213496565818787, 0.7112017869949341, 0.735316812992096, 0.7230384349822998, 0.719105064868927, 0.7315617799758911, 0.712412416934967, 0.7346246838569641, 0.721286416053772, 0.7336112260818481, 0.7125843167304993, 0.7322978377342224, 0.7411978244781494, 0.7217819094657898, 0.7249661684036255, 0.7508029937744141, 0.730343759059906, 0.7291936278343201], 'loss_bb': [0.687287449836731, 0.6873742341995239, 0.6975448131561279, 0.6926442384719849, 0.6971704959869385, 0.7083390951156616, 0.6987299919128418, 0.6938727498054504, 0.6891064047813416, 0.710136890411377, 0.6965637803077698, 0.7038024663925171, 0.7081465721130371, 0.7059897184371948, 0.6908268928527832, 0.6910354495048523, 0.6940746903419495, 0.7100236415863037, 0.6974671483039856, 0.7032625675201416, 0.7089315056800842, 0.7017815709114075, 0.7047857642173767, 0.7097731232643127, 0.7108651399612427, 0.7083536386489868, 0.714970588684082, 0.714926540851593, 0.7139217853546143, 0.6924275755882263, 0.7164666056632996, 0.7139139771461487, 0.7146806716918945, 0.7034685015678406, 0.7186117172241211, 0.7089993357658386, 0.7151094675064087, 0.7081248164176941, 0.7115813493728638, 0.7068505883216858, 0.7057949304580688, 0.7057104110717773, 0.7187182903289795, 0.7242244482040405, 0.7158671617507935, 0.7174245119094849, 0.695327639579773, 0.7174078822135925, 0.7038179636001587, 0.7237193584442139, 0.7309595942497253, 0.7095659971237183, 0.7086156010627747, 0.7244348526000977, 0.7241399884223938, 0.7250968813896179, 0.7098488807678223, 0.7193167805671692, 0.7222005128860474, 0.7371746301651001, 0.7135050296783447, 0.710416853427887, 0.724004328250885, 0.699338436126709, 0.732175886631012, 0.7201754450798035, 0.7150835394859314, 0.7242631912231445, 0.7300018072128296, 0.7088702917098999, 0.7195713520050049, 0.7241129875183105, 0.7210251092910767, 0.7180167436599731, 0.7100347280502319, 0.7187146544456482, 0.7243160605430603, 0.7300400733947754, 0.7434679269790649, 0.7227144837379456, 0.7273004651069641, 0.7364815473556519, 0.7213496565818787, 0.7112017869949341, 0.735316812992096, 0.7230384349822998, 0.719105064868927, 0.7315617799758911, 0.712412416934967, 0.7346246838569641, 0.721286416053772, 0.7336112260818481, 0.7125843167304993, 0.7322978377342224, 0.7411978244781494, 0.7217819094657898, 0.7249661684036255, 0.7508029937744141, 0.730343759059906, 0.7291936278343201]}, {'confidence_level': 0.7025, 'loss_g': [0.6770646572113037, 0.6829249262809753, 0.6929337382316589, 0.6858562231063843, 0.6853758096694946, 0.6795039772987366, 0.6868386268615723, 0.680523157119751, 0.6874012351036072, 0.6921889781951904, 0.6839879155158997, 0.686655580997467, 0.6848509311676025, 0.6842249035835266, 0.6845681071281433, 0.6918948888778687, 0.677202045917511, 0.689240038394928, 0.6824737191200256, 0.694987952709198, 0.6915229558944702, 0.6901202201843262, 0.6849867105484009, 0.6864691376686096, 0.6981262564659119, 0.6886358857154846, 0.6852889657020569, 0.6847087144851685, 0.6860809326171875, 0.6937013864517212, 0.7013967633247375, 0.6822696328163147, 0.6935528516769409, 0.680007815361023, 0.6974614262580872, 0.6898283362388611, 0.6854727864265442, 0.7046950459480286, 0.693902313709259, 0.6865454316139221, 0.7006915807723999, 0.6859403252601624, 0.6981762647628784, 0.6925162672996521, 0.6978136301040649, 0.6927495002746582, 0.7021411657333374, 0.7064229249954224, 0.6852080225944519, 0.6871702671051025, 0.6893625259399414, 0.6959280967712402, 0.6857046484947205, 0.691768229007721, 0.696191132068634, 0.6925955414772034, 0.6822108626365662, 0.691038191318512, 0.6904988288879395, 0.6936522126197815, 0.6981601715087891, 0.6919602751731873, 0.684558093547821, 0.692319393157959, 0.6964779496192932, 0.6941727995872498, 0.6985680460929871, 0.6893697381019592, 0.6902416348457336, 0.6824881434440613, 0.6914592981338501, 0.6982567310333252, 0.6943111419677734, 0.6828076243400574, 0.6857109665870667, 0.6958557963371277, 0.6978198289871216, 0.6956123113632202, 0.6973322629928589, 0.6975536346435547, 0.7042601108551025, 0.6936245560646057, 0.6831086277961731, 0.6915525794029236, 0.6978268027305603, 0.70162034034729, 0.685929000377655, 0.7048970460891724, 0.6986050009727478, 0.7025266885757446, 0.6985249519348145, 0.6871805787086487, 0.7056757211685181, 0.7040186524391174, 0.7010587453842163, 0.693321943283081, 0.6799006462097168, 0.6869512796401978, 0.6976295113563538, 0.6905653476715088], 'loss_bb': [0.6770646572113037, 0.6829249262809753, 0.6929337382316589, 0.6858562231063843, 0.6853758096694946, 0.6795039772987366, 0.6868386268615723, 0.680523157119751, 0.6874012351036072, 0.6921889781951904, 0.6839879155158997, 0.686655580997467, 0.6848509311676025, 0.6842249035835266, 0.6845681071281433, 0.6918948888778687, 0.677202045917511, 0.689240038394928, 0.6824737191200256, 0.694987952709198, 0.6915229558944702, 0.6901202201843262, 0.6849867105484009, 0.6864691376686096, 0.6981262564659119, 0.6886358857154846, 0.6852889657020569, 0.6847087144851685, 0.6860809326171875, 0.6937013864517212, 0.7013967633247375, 0.6822696328163147, 0.6935528516769409, 0.680007815361023, 0.6974614262580872, 0.6898283362388611, 0.6854727864265442, 0.7046950459480286, 0.693902313709259, 0.6865454316139221, 0.7006915807723999, 0.6859403252601624, 0.6981762647628784, 0.6925162672996521, 0.6978136301040649, 0.6927495002746582, 0.7021411657333374, 0.7064229249954224, 0.6852080225944519, 0.6871702671051025, 0.6893625259399414, 0.6959280967712402, 0.6857046484947205, 0.691768229007721, 0.696191132068634, 0.6925955414772034, 0.6822108626365662, 0.691038191318512, 0.6904988288879395, 0.6936522126197815, 0.6981601715087891, 0.6919602751731873, 0.684558093547821, 0.692319393157959, 0.6964779496192932, 0.6941727995872498, 0.6985680460929871, 0.6893697381019592, 0.6902416348457336, 0.6824881434440613, 0.6914592981338501, 0.6982567310333252, 0.6943111419677734, 0.6828076243400574, 0.6857109665870667, 0.6958557963371277, 0.6978198289871216, 0.6956123113632202, 0.6973322629928589, 0.6975536346435547, 0.7042601108551025, 0.6936245560646057, 0.6831086277961731, 0.6915525794029236, 0.6978268027305603, 0.70162034034729, 0.685929000377655, 0.7048970460891724, 0.6986050009727478, 0.7025266885757446, 0.6985249519348145, 0.6871805787086487, 0.7056757211685181, 0.7040186524391174, 0.7010587453842163, 0.693321943283081, 0.6799006462097168, 0.6869512796401978, 0.6976295113563538, 0.6905653476715088]}, {'confidence_level': 0.7275, 'loss_g': [0.6450888514518738, 0.6529870629310608, 0.6550173163414001, 0.6580496430397034, 0.6562022566795349, 0.6445171236991882, 0.6383239030838013, 0.6436848640441895, 0.6502714157104492, 0.6562673449516296, 0.6534278988838196, 0.6540895104408264, 0.6450973749160767, 0.6459546089172363, 0.6453438997268677, 0.6568525433540344, 0.6471353769302368, 0.6466091275215149, 0.6477497816085815, 0.6497616767883301, 0.6496596336364746, 0.6555999517440796, 0.6393154263496399, 0.6475989818572998, 0.6535192131996155, 0.6496269702911377, 0.6520545482635498, 0.6432982683181763, 0.6408414244651794, 0.6472456455230713, 0.6452104449272156, 0.6391263008117676, 0.6588809490203857, 0.6495596766471863, 0.6566276550292969, 0.6516380310058594, 0.6535347700119019, 0.6477051377296448, 0.6506021618843079, 0.6475875377655029, 0.6441956758499146, 0.6545760035514832, 0.659385085105896, 0.6533706784248352, 0.6451488733291626, 0.6561086773872375, 0.6416696906089783, 0.6395228505134583, 0.6453869938850403, 0.6545152068138123, 0.6557691097259521, 0.6458397507667542, 0.65455561876297, 0.6438943147659302, 0.6503865122795105, 0.6582993865013123, 0.6482635140419006, 0.646771252155304, 0.6463660597801208, 0.649360179901123, 0.6390722393989563, 0.6467152237892151, 0.6402794718742371, 0.6380608081817627, 0.642562985420227, 0.6520735025405884, 0.6634447574615479, 0.6508477330207825, 0.6498433947563171, 0.6440854668617249, 0.6499167084693909, 0.6506596803665161, 0.6504665613174438, 0.6554521322250366, 0.6435737609863281, 0.647477924823761, 0.6542320251464844, 0.6448236703872681, 0.6568661332130432, 0.6527011394500732, 0.6535346508026123, 0.6540013551712036, 0.6471036076545715, 0.6501840949058533, 0.6424800157546997, 0.6561973094940186, 0.6567853093147278, 0.6455284357070923, 0.6485247611999512, 0.6513471007347107, 0.648428738117218, 0.6437227725982666, 0.6506558060646057, 0.6554934978485107, 0.6531820297241211, 0.6506270170211792, 0.6336889266967773, 0.6357048749923706, 0.6438632011413574, 0.651137113571167], 'loss_bb': [0.6450888514518738, 0.6529870629310608, 0.6550173163414001, 0.6580496430397034, 0.6562022566795349, 0.6445171236991882, 0.6383239030838013, 0.6436848640441895, 0.6502714157104492, 0.6562673449516296, 0.6534278988838196, 0.6540895104408264, 0.6450973749160767, 0.6459546089172363, 0.6453438997268677, 0.6568525433540344, 0.6471353769302368, 0.6466091275215149, 0.6477497816085815, 0.6497616767883301, 0.6496596336364746, 0.6555999517440796, 0.6393154263496399, 0.6475989818572998, 0.6535192131996155, 0.6496269702911377, 0.6520545482635498, 0.6432982683181763, 0.6408414244651794, 0.6472456455230713, 0.6452104449272156, 0.6391263008117676, 0.6588809490203857, 0.6495596766471863, 0.6566276550292969, 0.6516380310058594, 0.6535347700119019, 0.6477051377296448, 0.6506021618843079, 0.6475875377655029, 0.6441956758499146, 0.6545760035514832, 0.659385085105896, 0.6533706784248352, 0.6451488733291626, 0.6561086773872375, 0.6416696906089783, 0.6395228505134583, 0.6453869938850403, 0.6545152068138123, 0.6557691097259521, 0.6458397507667542, 0.65455561876297, 0.6438943147659302, 0.6503865122795105, 0.6582993865013123, 0.6482635140419006, 0.646771252155304, 0.6463660597801208, 0.649360179901123, 0.6390722393989563, 0.6467152237892151, 0.6402794718742371, 0.6380608081817627, 0.642562985420227, 0.6520735025405884, 0.6634447574615479, 0.6508477330207825, 0.6498433947563171, 0.6440854668617249, 0.6499167084693909, 0.6506596803665161, 0.6504665613174438, 0.6554521322250366, 0.6435737609863281, 0.647477924823761, 0.6542320251464844, 0.6448236703872681, 0.6568661332130432, 0.6527011394500732, 0.6535346508026123, 0.6540013551712036, 0.6471036076545715, 0.6501840949058533, 0.6424800157546997, 0.6561973094940186, 0.6567853093147278, 0.6455284357070923, 0.6485247611999512, 0.6513471007347107, 0.648428738117218, 0.6437227725982666, 0.6506558060646057, 0.6554934978485107, 0.6531820297241211, 0.6506270170211792, 0.6336889266967773, 0.6357048749923706, 0.6438632011413574, 0.651137113571167]}, {'confidence_level': 0.7525, 'loss_g': [0.5963073968887329, 0.6027997732162476, 0.6031447649002075, 0.6027395725250244, 0.6030541062355042, 0.6018542051315308, 0.6067529320716858, 0.6050664782524109, 0.6098300814628601, 0.5969168543815613, 0.6043754816055298, 0.60877925157547, 0.6069750785827637, 0.5957211852073669, 0.6037182807922363, 0.6024414896965027, 0.6188747882843018, 0.6117244958877563, 0.6026749610900879, 0.6025847792625427, 0.6038159132003784, 0.5966581702232361, 0.6100944876670837, 0.6042670011520386, 0.6065117716789246, 0.5990416407585144, 0.612983226776123, 0.6029029488563538, 0.608876645565033, 0.6160820722579956, 0.5965529680252075, 0.5981413722038269, 0.602230966091156, 0.5995658040046692, 0.6040251851081848, 0.6033777594566345, 0.6080992817878723, 0.6079627275466919, 0.5986544489860535, 0.6020791530609131, 0.603280782699585, 0.6024592518806458, 0.603444516658783, 0.6008438467979431, 0.6125060319900513, 0.6038987636566162, 0.608131468296051, 0.6012681722640991, 0.5997923612594604, 0.6072957515716553, 0.5990961194038391, 0.6027874946594238, 0.6024495959281921, 0.6097020506858826, 0.5976371765136719, 0.6026839017868042, 0.5978443622589111, 0.6018229126930237, 0.6045160293579102, 0.5982383489608765, 0.6042022705078125, 0.6045565009117126, 0.6021088361740112, 0.5989330410957336, 0.5986929535865784, 0.5994905829429626, 0.603304386138916, 0.6003028154373169, 0.6075494885444641, 0.5952847599983215, 0.6115225553512573, 0.6024736762046814, 0.6016721725463867, 0.6073127388954163, 0.6085971593856812, 0.6000943183898926, 0.6114071011543274, 0.6047799587249756, 0.6061744689941406, 0.5960702896118164, 0.5995657444000244, 0.5959648489952087, 0.6012252569198608, 0.5949528217315674, 0.6091738343238831, 0.5990461111068726, 0.6039280891418457, 0.6080767512321472, 0.5981770157814026, 0.5945563316345215, 0.6033244729042053, 0.6032885909080505, 0.6046475172042847, 0.6036996841430664, 0.6147838830947876, 0.6112238764762878, 0.5996077060699463, 0.6046424508094788, 0.6071633100509644, 0.6132161617279053], 'loss_bb': [0.5963073968887329, 0.6027997732162476, 0.6031447649002075, 0.6027395725250244, 0.6030541062355042, 0.6018542051315308, 0.6067529320716858, 0.6050664782524109, 0.6098300814628601, 0.5969168543815613, 0.6043754816055298, 0.60877925157547, 0.6069750785827637, 0.5957211852073669, 0.6037182807922363, 0.6024414896965027, 0.6188747882843018, 0.6117244958877563, 0.6026749610900879, 0.6025847792625427, 0.6038159132003784, 0.5966581702232361, 0.6100944876670837, 0.6042670011520386, 0.6065117716789246, 0.5990416407585144, 0.612983226776123, 0.6029029488563538, 0.608876645565033, 0.6160820722579956, 0.5965529680252075, 0.5981413722038269, 0.602230966091156, 0.5995658040046692, 0.6040251851081848, 0.6033777594566345, 0.6080992817878723, 0.6079627275466919, 0.5986544489860535, 0.6020791530609131, 0.603280782699585, 0.6024592518806458, 0.603444516658783, 0.6008438467979431, 0.6125060319900513, 0.6038987636566162, 0.608131468296051, 0.6012681722640991, 0.5997923612594604, 0.6072957515716553, 0.5990961194038391, 0.6027874946594238, 0.6024495959281921, 0.6097020506858826, 0.5976371765136719, 0.6026839017868042, 0.5978443622589111, 0.6018229126930237, 0.6045160293579102, 0.5982383489608765, 0.6042022705078125, 0.6045565009117126, 0.6021088361740112, 0.5989330410957336, 0.5986929535865784, 0.5994905829429626, 0.603304386138916, 0.6003028154373169, 0.6075494885444641, 0.5952847599983215, 0.6115225553512573, 0.6024736762046814, 0.6016721725463867, 0.6073127388954163, 0.6085971593856812, 0.6000943183898926, 0.6114071011543274, 0.6047799587249756, 0.6061744689941406, 0.5960702896118164, 0.5995657444000244, 0.5959648489952087, 0.6012252569198608, 0.5949528217315674, 0.6091738343238831, 0.5990461111068726, 0.6039280891418457, 0.6080767512321472, 0.5981770157814026, 0.5945563316345215, 0.6033244729042053, 0.6032885909080505, 0.6046475172042847, 0.6036996841430664, 0.6147838830947876, 0.6112238764762878, 0.5996077060699463, 0.6046424508094788, 0.6071633100509644, 0.6132161617279053]}, {'confidence_level': 0.7775, 'loss_g': [0.555181086063385, 0.5585921406745911, 0.5633004307746887, 0.5543045997619629, 0.5545613169670105, 0.5603983402252197, 0.5571369528770447, 0.5597878694534302, 0.5669447183609009, 0.5586135387420654, 0.5609398484230042, 0.5581956505775452, 0.5654378533363342, 0.5539071559906006, 0.5563779473304749, 0.5548838973045349, 0.5654241442680359, 0.5546484589576721, 0.5637924671173096, 0.5582134127616882, 0.5584381818771362, 0.5581434369087219, 0.5537903308868408, 0.5602896809577942, 0.5590159296989441, 0.5572907328605652, 0.5584816932678223, 0.5595043301582336, 0.5518625974655151, 0.558116614818573, 0.56553715467453, 0.5615687966346741, 0.557317316532135, 0.5623083114624023, 0.5615894794464111, 0.5628702044487, 0.562885582447052, 0.5607630610466003, 0.553028404712677, 0.5644724369049072, 0.5604763627052307, 0.5622220039367676, 0.5613868236541748, 0.563893735408783, 0.5591660737991333, 0.5613111853599548, 0.5676833987236023, 0.5544725656509399, 0.5588265657424927, 0.5585103631019592, 0.5646585822105408, 0.5578626394271851, 0.5636287331581116, 0.5649906396865845, 0.5631576776504517, 0.5586614608764648, 0.5606756806373596, 0.5652806162834167, 0.5574831366539001, 0.5597221851348877, 0.564274251461029, 0.5565131902694702, 0.5633456707000732, 0.567669689655304, 0.5674083828926086, 0.5603622198104858, 0.5621489882469177, 0.5580139756202698, 0.5602658987045288, 0.5573049187660217, 0.5655400156974792, 0.5579023361206055, 0.5597342848777771, 0.5583915114402771, 0.5617168545722961, 0.557987630367279, 0.561118483543396, 0.5555112361907959, 0.5643136501312256, 0.5575962066650391, 0.5624111294746399, 0.5550592541694641, 0.5556430220603943, 0.5596581101417542, 0.5558837652206421, 0.5539021492004395, 0.563106119632721, 0.5618941783905029, 0.5530115962028503, 0.5617145299911499, 0.5608089566230774, 0.5591946244239807, 0.5554999113082886, 0.5554872751235962, 0.5573612451553345, 0.5634377002716064, 0.5640231370925903, 0.561824381351471, 0.5606818795204163, 0.5575014352798462], 'loss_bb': [0.555181086063385, 0.5585921406745911, 0.5633004307746887, 0.5543045997619629, 0.5545613169670105, 0.5603983402252197, 0.5571369528770447, 0.5597878694534302, 0.5669447183609009, 0.5586135387420654, 0.5609398484230042, 0.5581956505775452, 0.5654378533363342, 0.5539071559906006, 0.5563779473304749, 0.5548838973045349, 0.5654241442680359, 0.5546484589576721, 0.5637924671173096, 0.5582134127616882, 0.5584381818771362, 0.5581434369087219, 0.5537903308868408, 0.5602896809577942, 0.5590159296989441, 0.5572907328605652, 0.5584816932678223, 0.5595043301582336, 0.5518625974655151, 0.558116614818573, 0.56553715467453, 0.5615687966346741, 0.557317316532135, 0.5623083114624023, 0.5615894794464111, 0.5628702044487, 0.562885582447052, 0.5607630610466003, 0.553028404712677, 0.5644724369049072, 0.5604763627052307, 0.5622220039367676, 0.5613868236541748, 0.563893735408783, 0.5591660737991333, 0.5613111853599548, 0.5676833987236023, 0.5544725656509399, 0.5588265657424927, 0.5585103631019592, 0.5646585822105408, 0.5578626394271851, 0.5636287331581116, 0.5649906396865845, 0.5631576776504517, 0.5586614608764648, 0.5606756806373596, 0.5652806162834167, 0.5574831366539001, 0.5597221851348877, 0.564274251461029, 0.5565131902694702, 0.5633456707000732, 0.567669689655304, 0.5674083828926086, 0.5603622198104858, 0.5621489882469177, 0.5580139756202698, 0.5602658987045288, 0.5573049187660217, 0.5655400156974792, 0.5579023361206055, 0.5597342848777771, 0.5583915114402771, 0.5617168545722961, 0.557987630367279, 0.561118483543396, 0.5555112361907959, 0.5643136501312256, 0.5575962066650391, 0.5624111294746399, 0.5550592541694641, 0.5556430220603943, 0.5596581101417542, 0.5558837652206421, 0.5539021492004395, 0.563106119632721, 0.5618941783905029, 0.5530115962028503, 0.5617145299911499, 0.5608089566230774, 0.5591946244239807, 0.5554999113082886, 0.5554872751235962, 0.5573612451553345, 0.5634377002716064, 0.5640231370925903, 0.561824381351471, 0.5606818795204163, 0.5575014352798462]}, {'confidence_level': 0.8025, 'loss_g': [0.512351393699646, 0.5178206562995911, 0.5134344100952148, 0.5152456164360046, 0.517375111579895, 0.509867787361145, 0.5161107778549194, 0.5170049071311951, 0.5149269700050354, 0.514352560043335, 0.5149458646774292, 0.5147503614425659, 0.5177982449531555, 0.5177372694015503, 0.5147426128387451, 0.5142349600791931, 0.5150677561759949, 0.5136762857437134, 0.5131149888038635, 0.5149808526039124, 0.5181862115859985, 0.513217031955719, 0.5174649357795715, 0.5163869857788086, 0.5128099918365479, 0.5151082277297974, 0.5175411701202393, 0.5128790140151978, 0.5127685070037842, 0.5164839625358582, 0.5166391730308533, 0.5196009278297424, 0.5146819949150085, 0.5153835415840149, 0.5166288018226624, 0.51811683177948, 0.5142819285392761, 0.5135648846626282, 0.5206841826438904, 0.5123237371444702, 0.5129725933074951, 0.5114363431930542, 0.5151439309120178, 0.5164332985877991, 0.5148786306381226, 0.5143875479698181, 0.5134970545768738, 0.5152953863143921, 0.5127599239349365, 0.5208780765533447, 0.5094428658485413, 0.5212947726249695, 0.515450656414032, 0.5203194618225098, 0.5140368938446045, 0.5151415467262268, 0.5145509839057922, 0.5152941942214966, 0.5168423056602478, 0.5168423056602478, 0.5080022811889648, 0.5153868198394775, 0.5131811499595642, 0.5205926895141602, 0.5127584338188171, 0.517248272895813, 0.5156647562980652, 0.5184980630874634, 0.5170983672142029, 0.5141311883926392, 0.5145262479782104, 0.51516193151474, 0.5121845602989197, 0.5178533792495728, 0.5132694244384766, 0.5171419382095337, 0.5160930156707764, 0.5175331830978394, 0.5161954164505005, 0.5168864727020264, 0.5153295993804932, 0.513590931892395, 0.5184813737869263, 0.5122590065002441, 0.509391188621521, 0.5157182812690735, 0.5147128701210022, 0.5156404972076416, 0.5156509876251221, 0.5198163390159607, 0.5168526768684387, 0.514514684677124, 0.5097616910934448, 0.5135694146156311, 0.5170080661773682, 0.5143504738807678, 0.5140594840049744, 0.5104845762252808, 0.5129992365837097, 0.5156280398368835], 'loss_bb': [0.512351393699646, 0.5178206562995911, 0.5134344100952148, 0.5152456164360046, 0.517375111579895, 0.509867787361145, 0.5161107778549194, 0.5170049071311951, 0.5149269700050354, 0.514352560043335, 0.5149458646774292, 0.5147503614425659, 0.5177982449531555, 0.5177372694015503, 0.5147426128387451, 0.5142349600791931, 0.5150677561759949, 0.5136762857437134, 0.5131149888038635, 0.5149808526039124, 0.5181862115859985, 0.513217031955719, 0.5174649357795715, 0.5163869857788086, 0.5128099918365479, 0.5151082277297974, 0.5175411701202393, 0.5128790140151978, 0.5127685070037842, 0.5164839625358582, 0.5166391730308533, 0.5196009278297424, 0.5146819949150085, 0.5153835415840149, 0.5166288018226624, 0.51811683177948, 0.5142819285392761, 0.5135648846626282, 0.5206841826438904, 0.5123237371444702, 0.5129725933074951, 0.5114363431930542, 0.5151439309120178, 0.5164332985877991, 0.5148786306381226, 0.5143875479698181, 0.5134970545768738, 0.5152953863143921, 0.5127599239349365, 0.5208780765533447, 0.5094428658485413, 0.5212947726249695, 0.515450656414032, 0.5203194618225098, 0.5140368938446045, 0.5151415467262268, 0.5145509839057922, 0.5152941942214966, 0.5168423056602478, 0.5168423056602478, 0.5080022811889648, 0.5153868198394775, 0.5131811499595642, 0.5205926895141602, 0.5127584338188171, 0.517248272895813, 0.5156647562980652, 0.5184980630874634, 0.5170983672142029, 0.5141311883926392, 0.5145262479782104, 0.51516193151474, 0.5121845602989197, 0.5178533792495728, 0.5132694244384766, 0.5171419382095337, 0.5160930156707764, 0.5175331830978394, 0.5161954164505005, 0.5168864727020264, 0.5153295993804932, 0.513590931892395, 0.5184813737869263, 0.5122590065002441, 0.509391188621521, 0.5157182812690735, 0.5147128701210022, 0.5156404972076416, 0.5156509876251221, 0.5198163390159607, 0.5168526768684387, 0.514514684677124, 0.5097616910934448, 0.5135694146156311, 0.5170080661773682, 0.5143504738807678, 0.5140594840049744, 0.5104845762252808, 0.5129992365837097, 0.5156280398368835]}, {'confidence_level': 0.8275, 'loss_g': [0.4709606170654297, 0.47011125087738037, 0.47020789980888367, 0.4713405668735504, 0.4676048755645752, 0.46793434023857117, 0.4715547561645508, 0.46991926431655884, 0.4705987274646759, 0.47341638803482056, 0.46876728534698486, 0.471529483795166, 0.47096142172813416, 0.4699258804321289, 0.46859800815582275, 0.4731889069080353, 0.46963146328926086, 0.47051918506622314, 0.4749641716480255, 0.4713253080844879, 0.47112056612968445, 0.47350868582725525, 0.4689832031726837, 0.46931588649749756, 0.47033801674842834, 0.470183789730072, 0.4720674455165863, 0.4686635136604309, 0.4719199538230896, 0.47079578042030334, 0.4699626863002777, 0.4697839021682739, 0.46801838278770447, 0.4710052013397217, 0.47304657101631165, 0.4704833924770355, 0.47201165556907654, 0.47111445665359497, 0.47050487995147705, 0.47116464376449585, 0.4691961705684662, 0.47182023525238037, 0.4689368009567261, 0.46922704577445984, 0.47463104128837585, 0.47140994668006897, 0.4703271985054016, 0.4703427255153656, 0.47163936495780945, 0.4670909345149994, 0.4697461724281311, 0.4712575078010559, 0.470538467168808, 0.4723779559135437, 0.4699825346469879, 0.4714488089084625, 0.46921589970588684, 0.47297829389572144, 0.4720308482646942, 0.4698094427585602, 0.4716379940509796, 0.473940908908844, 0.47205111384391785, 0.4707649350166321, 0.4691322445869446, 0.47022801637649536, 0.47107791900634766, 0.47203749418258667, 0.4736841022968292, 0.47021836042404175, 0.47150304913520813, 0.47022315859794617, 0.4706762731075287, 0.46776366233825684, 0.468656986951828, 0.46749603748321533, 0.4702298641204834, 0.4685215950012207, 0.47469228506088257, 0.47187700867652893, 0.47124651074409485, 0.4706825613975525, 0.4693272113800049, 0.4706231355667114, 0.47059866786003113, 0.4676774740219116, 0.47053003311157227, 0.47081270813941956, 0.4718446731567383, 0.47242501378059387, 0.4699634909629822, 0.4715692698955536, 0.4701552987098694, 0.46860310435295105, 0.46895551681518555, 0.47115862369537354, 0.4677203595638275, 0.47162875533103943, 0.4682748317718506, 0.4699802100658417], 'loss_bb': [0.4709606170654297, 0.47011125087738037, 0.47020789980888367, 0.4713405668735504, 0.4676048755645752, 0.46793434023857117, 0.4715547561645508, 0.46991926431655884, 0.4705987274646759, 0.47341638803482056, 0.46876728534698486, 0.471529483795166, 0.47096142172813416, 0.4699258804321289, 0.46859800815582275, 0.4731889069080353, 0.46963146328926086, 0.47051918506622314, 0.4749641716480255, 0.4713253080844879, 0.47112056612968445, 0.47350868582725525, 0.4689832031726837, 0.46931588649749756, 0.47033801674842834, 0.470183789730072, 0.4720674455165863, 0.4686635136604309, 0.4719199538230896, 0.47079578042030334, 0.4699626863002777, 0.4697839021682739, 0.46801838278770447, 0.4710052013397217, 0.47304657101631165, 0.4704833924770355, 0.47201165556907654, 0.47111445665359497, 0.47050487995147705, 0.47116464376449585, 0.4691961705684662, 0.47182023525238037, 0.4689368009567261, 0.46922704577445984, 0.47463104128837585, 0.47140994668006897, 0.4703271985054016, 0.4703427255153656, 0.47163936495780945, 0.4670909345149994, 0.4697461724281311, 0.4712575078010559, 0.470538467168808, 0.4723779559135437, 0.4699825346469879, 0.4714488089084625, 0.46921589970588684, 0.47297829389572144, 0.4720308482646942, 0.4698094427585602, 0.4716379940509796, 0.473940908908844, 0.47205111384391785, 0.4707649350166321, 0.4691322445869446, 0.47022801637649536, 0.47107791900634766, 0.47203749418258667, 0.4736841022968292, 0.47021836042404175, 0.47150304913520813, 0.47022315859794617, 0.4706762731075287, 0.46776366233825684, 0.468656986951828, 0.46749603748321533, 0.4702298641204834, 0.4685215950012207, 0.47469228506088257, 0.47187700867652893, 0.47124651074409485, 0.4706825613975525, 0.4693272113800049, 0.4706231355667114, 0.47059866786003113, 0.4676774740219116, 0.47053003311157227, 0.47081270813941956, 0.4718446731567383, 0.47242501378059387, 0.4699634909629822, 0.4715692698955536, 0.4701552987098694, 0.46860310435295105, 0.46895551681518555, 0.47115862369537354, 0.4677203595638275, 0.47162875533103943, 0.4682748317718506, 0.4699802100658417]}]}\n",
      "\n",
      "\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "1      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "2      0.117747  0.04  0.138007  0.158160  0.026483 -0.222038  0.940031   \n",
      "3      0.117747  0.04  0.138007 -0.626122  0.026483 -0.222038 -0.167105   \n",
      "4      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167105   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "99996  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "99997  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "99998  0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "99999  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "1     -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.501645   \n",
      "2      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "3      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "4      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "99996  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99997  0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "99998 -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "99999 -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0     -0.589114 -0.014229  0.054317 -0.083356 -0.877169  0.142732  0.128289  \n",
      "1      0.922754 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.128289  \n",
      "2     -0.589114 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.147772  \n",
      "3      0.922754 -0.014229  0.054317  0.702949 -0.877169  0.142732  0.147772  \n",
      "4      0.922754 -0.014229  1.399837  0.702950  0.356885 -1.060455  0.128289  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  0.054317  0.702950 -0.877169 -1.060455  0.147772  \n",
      "99996 -0.589114 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.147772  \n",
      "99997 -0.589114 -0.014229  0.054317  0.702949 -0.877169 -1.060455  0.128289  \n",
      "99998 -0.589114 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.128289  \n",
      "99999 -0.589114 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.147772  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007  0.158160  0.026483  0.136601 -0.167104   \n",
      "1      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601  0.940031   \n",
      "2      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167104   \n",
      "3      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "4      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167105   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167105   \n",
      "99996  0.117747  0.04  0.138007  0.158160  0.026483  0.136601 -0.167104   \n",
      "99997  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "99998  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601  0.940031   \n",
      "99999  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "1      0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "2      0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "3      0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "4      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "99996  0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "99997 -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "99998 -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501645   \n",
      "99999 -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0      0.922754 -0.014229  1.399837 -0.083356  0.356885 -1.060455  0.128289  \n",
      "1      0.922754 -0.014229  0.054317 -0.083356  0.356885 -1.060455  0.147773  \n",
      "2      0.922754 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.128289  \n",
      "3      0.922754 -0.014229  0.054317 -0.083356 -0.877169  0.142732  0.128289  \n",
      "4     -0.589114 -0.014229  0.054318 -0.083356  0.356885  0.142732  0.128289  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  0.054317 -0.083356  0.356885  0.142732  0.147772  \n",
      "99996  0.922754 -0.014229  0.054317  0.702950 -0.877169  0.142732  0.128289  \n",
      "99997  0.922754 -0.014229  0.054317  0.702949  0.356885  0.142732  0.147772  \n",
      "99998 -0.589114 -0.014229  0.054317 -0.254394 -0.877169 -1.060455  0.147772  \n",
      "99999 -0.589114 -0.014229  1.399837  0.702949 -0.877169 -1.060455  0.128289  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007  0.158159  0.026483  0.136601 -0.167105   \n",
      "1      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167105   \n",
      "2      0.117747  0.04  0.138007  0.158159  0.026483  0.136601 -0.167105   \n",
      "3      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "4      0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167104   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "99996  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "99997  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038  0.940031   \n",
      "99998  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038  0.940031   \n",
      "99999  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167105   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0     -0.310529  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "1     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "2     -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "3      0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "4     -0.310529  0.024025  0.07663  ... -0.044889 -0.656367  0.501646   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995  0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "99996 -0.310529  0.024025  0.07663  ... -0.044889 -0.656367  0.501646   \n",
      "99997  0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "99998  0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "99999  0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0     -0.589114 -0.014229  0.054317 -0.254394  0.356885  0.142732  0.147772  \n",
      "1      0.922754 -0.014229  1.399837  0.702950  0.356885  0.142732  0.147772  \n",
      "2      0.922754 -0.014229  0.054317  0.702949  0.356885  0.142732  0.128289  \n",
      "3     -0.589114 -0.014229  0.054317 -0.083356  0.356885  0.142732  0.147772  \n",
      "4     -0.589114 -0.014229  0.054317  0.702950  0.356885 -1.060455  0.128288  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  1.399837 -0.083356 -0.877169  0.142732  0.147772  \n",
      "99996 -0.589114 -0.014229  1.399837 -0.083356  0.356885  0.142732  0.147772  \n",
      "99997  0.922754 -0.014229  0.054317 -0.254394  0.356885 -1.060455  0.128289  \n",
      "99998 -0.589114 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.128289  \n",
      "99999  0.922754 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.147772  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "1      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167104   \n",
      "2      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601  0.940031   \n",
      "3      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "4      0.117747  0.04  0.138007  0.158159  0.026483  0.136601 -0.167105   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "99996  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167105   \n",
      "99997  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167105   \n",
      "99998  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167104   \n",
      "99999  0.117747  0.04  0.138007  0.158159  0.026483  0.136601  0.940031   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "1      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "2      0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "3     -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "4      0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "99996 -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "99997  0.080413  0.024025  0.07663  ... -0.044889 -0.656367  0.501646   \n",
      "99998 -0.310529  0.024025 -0.47372  ... -0.044889 -0.656367  0.501646   \n",
      "99999 -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0     -0.589114 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.128289  \n",
      "1      0.922754 -0.014229  0.054317 -0.254394 -0.877169 -1.060455  0.128289  \n",
      "2      0.922754 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.128289  \n",
      "3     -0.589114 -0.014229  0.054317 -0.083356 -0.877169  0.142732  0.128289  \n",
      "4      0.922754 -0.014229  0.054317 -0.083356 -0.877169 -1.060455  0.147773  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  0.054317 -0.083356  0.356885  0.142732  0.128289  \n",
      "99996 -0.589114 -0.014229  0.054317 -0.083356 -0.877169  0.142732  0.147772  \n",
      "99997 -0.589114 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.128289  \n",
      "99998 -0.589114 -0.014229  0.054317 -0.254394  0.356885  0.142732  0.147772  \n",
      "99999  0.922754 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.128289  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "1      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "2      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167105   \n",
      "3      0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "4      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "99996  0.117747  0.04  0.138007  0.158160  0.026483  0.136601 -0.167104   \n",
      "99997  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167104   \n",
      "99998  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167104   \n",
      "99999  0.117747  0.04  0.138007  0.158159  0.026483  0.136601  0.940031   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0     -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "1      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "2      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "3     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "4      0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "99996 -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99997  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99998  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "99999  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0     -0.589114 -0.014229  0.054317 -0.254394 -0.877169 -1.060455  0.128289  \n",
      "1      0.922754 -0.014229  1.399837 -0.254394 -0.877169 -1.060455  0.147772  \n",
      "2      0.922754 -0.014229  1.399837  0.702949 -0.877169  0.142732  0.128289  \n",
      "3     -0.589114 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.147772  \n",
      "4      0.922754 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.147772  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995  0.922754 -0.014229  0.054317 -0.083356 -0.877169 -1.060455  0.147772  \n",
      "99996 -0.589114 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.128289  \n",
      "99997  0.922754 -0.014229  0.054317  0.702949  0.356885 -1.060455  0.128289  \n",
      "99998 -0.589114 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.128289  \n",
      "99999  0.922754 -0.014229  0.054317 -0.083356 -0.877169 -1.060455  0.147772  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167105   \n",
      "1      0.117747  0.04  0.138007  0.158160  0.026483 -0.222038  0.940031   \n",
      "2      0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "3      0.117747  0.04  0.138007  0.158159  0.026483  0.136601  0.940031   \n",
      "4      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167104   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "99996  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601  0.940031   \n",
      "99997  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "99998  0.117747  0.04  0.138007 -0.626122  0.026483 -0.222038  0.940031   \n",
      "99999  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0     -0.310529  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "1      0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "2     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "3      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "4      0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.501645   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99996 -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "99997 -0.310529  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "99998  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "99999  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0      0.922754 -0.014229  0.054317 -0.254394  0.356885 -1.060455  0.147772  \n",
      "1      0.922754 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.147772  \n",
      "2      0.922754 -0.014229  1.399837 -0.254394  0.356884  0.142732  0.147772  \n",
      "3      0.922754 -0.014229  1.399837  0.702950 -0.877169 -1.060455  0.128289  \n",
      "4      0.922754 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.128289  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  1.399837 -0.254394 -0.877169 -1.060455  0.128288  \n",
      "99996  0.922754 -0.014229  0.054317 -0.254394  0.356885 -1.060455  0.128289  \n",
      "99997  0.922754 -0.014229  1.399837 -0.254394  0.356885  0.142732  0.128289  \n",
      "99998 -0.589114 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.128289  \n",
      "99999  0.922754 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.128289  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "1      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167105   \n",
      "2      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601  0.940031   \n",
      "3      0.117747  0.04  0.138007  0.158159  0.026483  0.136601  0.940031   \n",
      "4      0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "99996  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167105   \n",
      "99997  0.117747  0.04  0.138007  0.158159  0.026483  0.136601 -0.167104   \n",
      "99998  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167104   \n",
      "99999  0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0      0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "1     -0.310529  0.024025  0.07663  ... -0.044889 -0.656366  0.501645   \n",
      "2     -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "3     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "4     -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99996  0.080413  0.024025  0.07663  ... -0.044889 -0.656367  0.031277   \n",
      "99997  0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "99998  0.080413  0.024025 -0.47372  ... -0.044889 -0.656367  0.501646   \n",
      "99999  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0      0.922754 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.128289  \n",
      "1      0.922754 -0.014229  0.054317 -0.083356  0.356885 -1.060455  0.128289  \n",
      "2      0.922754 -0.014229  0.054317  0.702949  0.356885  0.142732  0.128289  \n",
      "3     -0.589114 -0.014229  1.399837 -0.254394  0.356885 -1.060455  0.128289  \n",
      "4     -0.589114 -0.014229  1.399837 -0.254394 -0.877169  0.142732  0.147772  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995  0.922754 -0.014229  1.399837 -0.083356  0.356885  0.142732  0.147772  \n",
      "99996 -0.589114 -0.014229  0.054317 -0.254394  0.356885  0.142732  0.128289  \n",
      "99997  0.922754 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.128289  \n",
      "99998  0.922754 -0.014229  0.054317 -0.083356 -0.877169 -1.060455  0.128289  \n",
      "99999 -0.589114 -0.014229  1.399837 -0.254394 -0.877169  0.142732  0.128288  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "1      0.117747  0.04  0.138007 -0.626122  0.026483 -0.222038 -0.167104   \n",
      "2      0.117747  0.04  0.138007  0.158160  0.026483 -0.222038  0.940031   \n",
      "3      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167105   \n",
      "4      0.117747  0.04  0.138007  0.158159  0.026483  0.136601  0.940031   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167105   \n",
      "99996  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "99997  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038  0.940031   \n",
      "99998  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167105   \n",
      "99999  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167105   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "1     -0.310529  0.024025 -0.47372  ... -0.044889 -0.656366  0.501646   \n",
      "2     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "3     -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501645   \n",
      "4     -0.310529  0.024025  0.07663  ... -0.044889 -0.656367  0.031277   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995 -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "99996 -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "99997  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99998  0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "99999  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0     -0.589114 -0.014229  1.399837  0.702949  0.356885  0.142732  0.128289  \n",
      "1     -0.589114 -0.014229  1.399837  0.702950 -0.877169  0.142732  0.147772  \n",
      "2      0.922754 -0.014229  0.054318  0.702949  0.356884  0.142732  0.128289  \n",
      "3      0.922754 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.147772  \n",
      "4     -0.589114 -0.014229  1.399837 -0.083356 -0.877169  0.142732  0.147773  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.128289  \n",
      "99996  0.922754 -0.014229  1.399837  0.702949 -0.877169  0.142732  0.128289  \n",
      "99997  0.922754 -0.014229  0.054317 -0.254394 -0.877169 -1.060455  0.128289  \n",
      "99998  0.922754 -0.014229  1.399837 -0.254394 -0.877169  0.142732  0.147772  \n",
      "99999  0.922754 -0.014229  0.054317 -0.254394 -0.877169 -1.060455  0.128289  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007  0.158159  0.026483  0.136601 -0.167105   \n",
      "1      0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "2      0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "3      0.117747  0.04  0.138007 -0.626122  0.026483 -0.222038 -0.167104   \n",
      "4      0.117747  0.04  0.138007  0.158160  0.026483  0.136601 -0.167104   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007  0.158160  0.026483  0.136601 -0.167104   \n",
      "99996  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "99997  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601  0.940031   \n",
      "99998  0.117747  0.04  0.138007 -0.626123  0.026483 -0.222038 -0.167104   \n",
      "99999  0.117747  0.04  0.138007  0.158160  0.026483  0.136601  0.940031   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0      0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "1     -0.310529  0.024025  0.07663  ... -0.044889 -0.656367  0.501646   \n",
      "2      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "3     -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "4      0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.501645   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99996  0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.501646   \n",
      "99997  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "99998  0.080413  0.024025 -0.47372  ... -0.044889 -0.656366  0.031277   \n",
      "99999  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0     -0.589114 -0.014229  0.054317 -0.083356 -0.877169  0.142732  0.128289  \n",
      "1     -0.589114 -0.014229  0.054317  0.702949  0.356885 -1.060455  0.128289  \n",
      "2     -0.589114 -0.014229  0.054317 -0.083356  0.356885  0.142732  0.128289  \n",
      "3      0.922754 -0.014229  0.054317  0.702949  0.356885  0.142732  0.147772  \n",
      "4     -0.589114 -0.014229  0.054317 -0.254394 -0.877169  0.142732  0.128289  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  0.054317 -0.254394 -0.877169 -1.060455  0.147772  \n",
      "99996  0.922754 -0.014229  1.399837  0.702950 -0.877169 -1.060455  0.128289  \n",
      "99997  0.922754 -0.014229  0.054318  0.702949 -0.877169 -1.060455  0.128289  \n",
      "99998  0.922754 -0.014229  1.399837 -0.083356  0.356885  0.142732  0.147772  \n",
      "99999 -0.589114 -0.014229  0.054317 -0.254394  0.356885 -1.060455  0.147772  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n",
      "\tGenerate samples to same dist...\n",
      "gen data\n",
      "\n",
      "             0     1         2         3         4         5         6   \\\n",
      "0      0.117747  0.04  0.138007  0.158160  0.026483 -0.222038 -0.167104   \n",
      "1      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038  0.940031   \n",
      "2      0.117747  0.04  0.138007 -0.626122  0.026483 -0.222038 -0.167104   \n",
      "3      0.117747  0.04  0.138007  0.158160  0.026483  0.136601 -0.167104   \n",
      "4      0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167105   \n",
      "...         ...   ...       ...       ...       ...       ...       ...   \n",
      "99995  0.117747  0.04  0.138007 -0.626123  0.026483  0.136601 -0.167104   \n",
      "99996  0.117747  0.04  0.138007  0.158160  0.026483 -0.222038  0.940031   \n",
      "99997  0.117747  0.04  0.138007  0.158159  0.026483  0.136601  0.940031   \n",
      "99998  0.117747  0.04  0.138007  0.158159  0.026483 -0.222038 -0.167104   \n",
      "99999  0.117747  0.04  0.138007  0.158159  0.026483  0.136601 -0.167104   \n",
      "\n",
      "             7         8        9   ...        14        15        16  \\\n",
      "0     -0.310529  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "1     -0.310529  0.024025 -0.47372  ... -0.044889  0.453570  0.031277   \n",
      "2     -0.310529  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "3      0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "4      0.080413  0.024025 -0.47372  ... -0.044889  0.453570  0.501646   \n",
      "...         ...       ...      ...  ...       ...       ...       ...   \n",
      "99995  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "99996  0.080413  0.024025  0.07663  ... -0.044889  0.453570  0.031277   \n",
      "99997  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.031277   \n",
      "99998  0.080413  0.024025 -0.47372  ... -0.044889 -0.656367  0.501646   \n",
      "99999  0.080413  0.024025  0.07663  ... -0.044889 -0.656366  0.501646   \n",
      "\n",
      "             17        18        19        20        21        22        23  \n",
      "0      0.922754 -0.014229  1.399837 -0.254394 -0.877169  0.142732  0.128289  \n",
      "1      0.922754 -0.014229  1.399837  0.702949 -0.877169 -1.060455  0.128289  \n",
      "2     -0.589114 -0.014229  1.399837  0.702949 -0.877169  0.142732  0.147772  \n",
      "3     -0.589114 -0.014229  1.399837 -0.254394 -0.877169 -1.060455  0.147772  \n",
      "4     -0.589114 -0.014229  1.399837 -0.083356 -0.877169 -1.060455  0.147772  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "99995 -0.589114 -0.014229  0.054317 -0.083356 -0.877169 -1.060455  0.128289  \n",
      "99996 -0.589114 -0.014229  1.399837 -0.083356  0.356885 -1.060455  0.128289  \n",
      "99997 -0.589114 -0.014229  0.054317 -0.083356 -0.877169  0.142732  0.128289  \n",
      "99998 -0.589114 -0.014229  1.399837  0.702950  0.356885 -1.060455  0.147772  \n",
      "99999 -0.589114 -0.014229  0.054317  0.702949  0.356885 -1.060455  0.147772  \n",
      "\n",
      "[100000 rows x 24 columns]\n",
      "bucket indexes which we didnt find to them enough gen samples\n",
      " \n",
      "index 0 values left 3\n",
      "\n",
      "index 1 values left 4\n",
      "\n",
      "index 2 values left 5\n",
      "\n",
      "index 3 values left 29\n",
      "\n",
      "index 4 values left 43\n",
      "\n",
      "index 6 values left 90\n",
      "\n",
      "index 7 values left 167\n",
      "\n",
      "train samples did not had gendata samp in their bin, and therefore not used: 341/500\n",
      "\n",
      "ans\n",
      "\n",
      "(159,)\n",
      "train_ans\n",
      "\n",
      "(159,)\n"
     ]
    }
   ],
   "source": [
    "#need to combine with table creation part, or put one of them in comment\n",
    "#in order to run one of them(because both of them train the model )\n",
    "\n",
    "\n",
    "import xlsxwriter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#create excel file\n",
    "workbook = xlsxwriter.Workbook('German_confidences.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#keeps train and test seperatly\n",
    "#clf.fit(X_train_data, y_train_data)\n",
    "#y_prob_train_data = rf.predict_proba(X_train_data)\n",
    "y_conf_train_data = y_conf_train  # confidence scores\n",
    "print(\"y_conf_train_data\\n\")\n",
    "\n",
    "#clf.fit(X_test_data, y_test_data)\n",
    "y_prob_test_data = rf.predict_proba(X_test_data)\n",
    "y_conf_test_data = y_prob_test_data[:, 0]  # confidence scores\n",
    "print(\"y_conf_test_data\\n\")\n",
    "#print(y_conf_train)\n",
    "#keeped\n",
    "\n",
    "\n",
    "\n",
    "# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\n",
    "# X_train = X_all\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# train CTGAN\n",
    "z_features = get_noise_features(X_train, categorical_features)\n",
    "z_rows = int(0.25 * X_train.shape[0])\n",
    "z = gen_random_noise(shape=(z_rows, z_features))\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "#epochs=100\n",
    "#confidence_level = c\n",
    "gen_lr = 2e-5\n",
    "loss = 'log'\n",
    "\n",
    "#now ctgan synthesizer gets conf levels as input\n",
    "rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n",
    "                            blackbox_model=rf,\n",
    "                            preprocessing_pipeline=preprocessor,\n",
    "                            bb_loss=loss,\n",
    "                            confidence_levels=top_c_lst\n",
    "                            )\n",
    "#print(rf_ctgan.confidence_levels)\n",
    "\n",
    "print(f\"Training CTGAN for c list = {top_c_lst} ...\")\n",
    "#removed conf level from fit input arguements\n",
    "allconf_levels_hist = rf_ctgan.fit(train_data=z,\n",
    "                                   epochs=epochs,\n",
    "                                   gen_lr=gen_lr,\n",
    "                                   verbose=False\n",
    "                                  )\n",
    "\n",
    "print(\"\\nlosses history of all confidence levels:\\n\")\n",
    "print(allconf_levels_hist)\n",
    "print(\"\\n\\n\")\n",
    "# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\n",
    "# plot_losses(hist, title=f'{dataset} loss, c = {confidence_level}')\n",
    "# print()\n",
    "\n",
    "#allsamplesInv = 0\n",
    "#allDataFrames = []\n",
    "#allgeninv= 0\n",
    "#alldataframescoverage =[]\n",
    "#alldataframesprecision =[]\n",
    "freqsCounter = 0\n",
    "#add here conf loop, send each conf to samples as input each loop\n",
    "\n",
    "#to delete\n",
    "#c= top_c_lst[0]\n",
    "#top_c_lst = [c]\n",
    "#delete above\n",
    "for c in top_c_lst:\n",
    "    print(\"\\tGenerate samples to same dist...\")\n",
    "    # Generate samples to same dist\n",
    "    samples = 100000\n",
    "    gen_data,gen_fakeacts = rf_ctgan.sample(samples,c)\n",
    "    y_prob = rf.predict_proba(gen_data)\n",
    "    y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "\n",
    "    print(\"gen data\\n\")\n",
    "    print(gen_data)\n",
    "\n",
    "    # ans is the indices of gen_data to make the same dist\n",
    "    ans,train_ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "    gen_data_same_dist = gen_data.iloc[ans]\n",
    "    y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\n",
    "    # inverse the generated data\n",
    "    scaler = get_scaler(preprocessor)\n",
    "    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "    #gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "\n",
    "    #find kmean to geninv ndarray\n",
    "    kmeans = KMeans(n_clusters=1).fit(gen_data_inv)\n",
    "    gen_data_inv_centroide = kmeans.cluster_centers_\n",
    "\n",
    "    #create new worksheet, excel for bin Contains Conf c\n",
    "    name =\"bin Contains Conf \"+str(c)\n",
    "    worksheet = workbook.add_worksheet(name)\n",
    "\n",
    "    #create columns name of excel worksheet\n",
    "    worksheet.write('A1', 'TR/TS_index')\n",
    "    worksheet.write('B1', 'train/test')\n",
    "    worksheet.write('C1', 'cosin_similarity')\n",
    "\n",
    "    #fill the current worksheet excel\n",
    "    row =1\n",
    "    col = 0\n",
    "    #isTrain= True\n",
    "    #j=0\n",
    "    # Iterate over the data and write it out row by row.\n",
    "    #train_counter = 0\n",
    "    #print(x_train_data[0])\n",
    "    #print(x_train_data[0].shape)\n",
    "    #print(gen_data_inv_centroide)\n",
    "    #print(gen_data_inv_centroide.shape)\n",
    "    for sample_idx, sample_conf in enumerate (y_conf_train_data):\n",
    "        #if the conf of data is in the current interval\n",
    "        #so we want to add it to the excel bin conf\n",
    "        if(idxs.contains(sample_conf)[freqsCounter]):\n",
    "            #print(\"train entered to excel\\n\")\n",
    "            #down i reshaped to make the train data[freqcount]\n",
    "            #to be in 2D as needed(was 1D) and 1 -1 to make it (1,24)\n",
    "            csm = cosine_similarity(gen_data_inv_centroide, X_train_data[sample_idx].reshape(1,-1)).squeeze()\n",
    "            #print(csm)\n",
    "            #print(sample_idx)\n",
    "            #print(row)\n",
    "            #print(col)\n",
    "            worksheet.write(row, col, sample_idx)\n",
    "            worksheet.write(row, col + 1, 'train')\n",
    "            worksheet.write(row, col + 2, csm)\n",
    "           # isTrain = !isTrain\n",
    "            row += 1\n",
    "            #j+=1\n",
    "            #train_counter+=1\n",
    "\n",
    "\n",
    "\n",
    "    col = 0\n",
    "    #isTrain= True\n",
    "    #j=0\n",
    "    # Iterate over the data and write it out row by row.\n",
    "    #test_counter = 0\n",
    "    #print(y_conf_train_data)\n",
    "    #print(y_conf_test_data)\n",
    "\n",
    "    for sample_idx, sample_conf in enumerate (y_conf_test_data):\n",
    "        #print(\"in test loop\\n\")\n",
    "        #if the conf of data is in the current interval bin\n",
    "        #so we want to add it to the excel bin conf\n",
    "        if(idxs.contains(sample_conf)[freqsCounter]):\n",
    "            #print(\"test entered to excel\\n\")\n",
    "            csm = cosine_similarity(gen_data_inv_centroide, X_test_data[sample_idx].reshape(1,-1)).squeeze()\n",
    "            worksheet.write(row, col, sample_idx)\n",
    "            worksheet.write(row, col + 1, 'test')\n",
    "            worksheet.write(row, col + 2, csm)\n",
    "           # isTrain = !isTrain\n",
    "            row += 1\n",
    "            #j+=1\n",
    "            #test_counter+=1\n",
    "\n",
    "\n",
    "\n",
    "    freqsCounter=freqsCounter+1\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "    #calcute and create excel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}