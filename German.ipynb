{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import Counter\n",
    "import IPython\n",
    "from IPython.core.display import display\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODELS_PATH = './models'\n",
    "dataset = 'german'\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Load data, preprocess, and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, le = read_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 24)\n",
      "(500, 24)\n",
      "(500,)\n",
      "(500,)\n",
      "model score: 0.762\n"
     ]
    }
   ],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "categorical_features=[]\n",
    "preprocessor = get_preprocessor(X, categorical_features)\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', rf)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=seed)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "#keep train alone and test alone for create excel file in code\n",
    "#further in the code\n",
    "X_train_data = X_train\n",
    "X_test_data = X_test\n",
    "y_train_data = y_train\n",
    "y_test_data= y_test\n",
    "# will used it after/before training\n",
    "\n",
    "#print(X_train_data[0])\n",
    "\n",
    "#X_train_data\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Plot confidence scores for all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf_train\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#putted in comment the line below, so X_train will not be the whole data\n",
    "#X_train, y_train = X, y\n",
    "#clf.fit(X_train, y_train)\n",
    "#the comment above was allready calc one cell before\n",
    "y_prob = rf.predict_proba(X_train)\n",
    "y_conf_train = y_prob[:, 0]  # confidence scores\n",
    "print(\"y_conf_train\\n\")\n",
    "#print(y_conf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "0\n",
    "plot_confidence_levels(y_conf_train, \"Confidence scores for X_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Select C as the middle of top intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   4   5  29  43 101  90 167  48  10]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Create bucket (intervals) from generated data\n",
    "top_c = 10\n",
    "conf_bucktes = pd.value_counts(y_conf_train, bins=10, sort=False)\n",
    "idxs, freqs = conf_bucktes.index, conf_bucktes.values\n",
    "#print(idxs[0])\n",
    "akaka=idxs.contains(0.6)\n",
    "print(freqs)\n",
    "freqsSum = freqs.sum()\n",
    "print(freqsSum)\n",
    "\n",
    "\n",
    "# extract top_c intervals by frequency values\n",
    "intervals_idxs = np.argsort(freqs)[::-1][:top_c]\n",
    "top_c_intervals = idxs[intervals_idxs]\n",
    "\n",
    "# create top_c_lst as the middle of the interval\n",
    "top_c_lst = [(interval.right + interval.left)/2 for interval in top_c_intervals]\n",
    "top_c_lst = sorted(round(x, 4) for x in top_c_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.602, 0.6275, 0.6525, 0.6775, 0.7025, 0.7275, 0.7525, 0.7775, 0.8025, 0.8275]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_c_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Train one CTGAN with middle of intervals (10 Confidence levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\\n# X_train = X_all\\nX_train_pd = pd.DataFrame(X_train)\\n\\n\\n\\n# train CTGAN\\nz_features = get_noise_features(X_train, categorical_features)\\nz_rows = int(0.25 * X_train.shape[0])\\nz = gen_random_noise(shape=(z_rows, z_features))\\n\\nbatch_size = 50\\nepochs = 50\\n#confidence_level = c\\ngen_lr = 2e-5\\nloss = \\'log\\'\\n\\n#now ctgan synthesizer gets conf levels as input\\nrf_ctgan = CTGANSynthesizer(batch_size=batch_size,\\n                            blackbox_model=rf,\\n                            preprocessing_pipeline=preprocessor,\\n                            bb_loss=loss,\\n                            confidence_levels=top_c_lst\\n                            )\\n#print(rf_ctgan.confidence_levels)\\n\\nprint(f\"Training CTGAN for c list = {top_c_lst} ...\")\\n#removed conf level from fit input arguements\\nallconf_levels_hist = rf_ctgan.fit(train_data=z,\\n                                   epochs=epochs,\\n                                   gen_lr=gen_lr,\\n                                   verbose=False\\n                                  )\\n\\n#print(\"\\nhistory of all confidence levels:\\n\")\\n#print(allconf_levels_hist)\\n#print(\"\\n\\n\")\\n# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\\n# plot_losses(hist, title=f\\'{dataset} loss, c = {confidence_level}\\')\\n# print()\\n\\n#allsamplesInv = 0\\n#allDataFrames = []\\n#allgeninv= 0\\nalldataframescoverage =[]\\nalldataframesprecision =[]\\nfreqsCounter = 0\\n#add here conf loop, send each conf to samples as input each loop\\nfor c in top_c_lst:\\n    print(\"\\tGenerate samples to same dist...\")\\n    # Generate samples to same dist\\n    samples = 100000\\n    #samples = 200000\\n    gen_data,gen_fakeacts = rf_ctgan.sample(samples,c)\\n    y_prob = rf.predict_proba(gen_data)\\n    print(y_prob)\\n    y_conf_gen = y_prob[:, 0]  # confidence scores\\n    #print(y_conf_gen)\\n    #print(y_conf_train)\\n\\n    #train_bucktes_gen = pd.value_counts(y_conf_gen, bins=10, sort=False)\\n    #print(train_bucktes_gen)\\n    # ans is the indices of gen_data to make the same dist\\n    ans,train_ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\\n    gen_data_same_dist = gen_data.iloc[ans]\\n    y_conf_gen_same_dist = y_conf_gen[ans]\\n\\n    #take only relevant sample from train\\n    relevant_train_data = X_train_pd.iloc[train_ans]\\n    relevant_y_conf_train = y_conf_train[train_ans]\\n\\n\\n\\n    # inverse the generated data\\n    scaler = get_scaler(preprocessor)\\n    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\\n    gen_data_inv = pd.DataFrame(gen_data_inv)\\n\\n    #calc all inv\\n    #freqs[freqsCounter] probably in our the gen size data train\\n    # in the interval bin that c in it\\n    #allgeninv = allgeninv + freqs[freqsCounter]\\n    #calc end\\n\\n    # y_conf_gen_same_dist, gen_data_inv what we want\\n    # results\\n    # E. Calculate coverage for each similarity and conf diff thresholds\\n\\n    #sum all geninvsamples\\n    #allsamplesInv =allsamplesInv + gen_data_inv.size()\\n\\n    print(\"gen_data\")\\n    print(gen_data_inv.shape)\\n    print(\"relevant_X_train\")\\n    print(relevant_train_data.shape)\\n    print(\"y_conf_gen\")\\n    print(y_conf_gen_same_dist.shape)\\n    print(\"relevant_y_conf_train\")\\n    print(relevant_y_conf_train.shape)\\n\\n\\n    print(f\"\\tWorking on results...\")\\n    results,coverage, precision = table(gen_data_inv, relevant_train_data, y_conf_gen_same_dist, relevant_y_conf_train)\\n\\n    print(\"datagen inv size:\")\\n    print(gen_data_inv.size)\\n    print(\"\\n\")\\n    print(\"current bin size:\")\\n    print(freqs[freqsCounter])\\n    print(\"\\n\")\\n\\n    #keep all data frames\\n    alldataframescoverage.append([coverage,freqs[freqsCounter]])\\n    alldataframesprecision.append([precision,freqs[freqsCounter]])\\n   # allDataFrames.append(results)\\n\\n    print(f\"\\tResults for confidence level = {c}\")\\n    display(results)\\n    freqsCounter=freqsCounter+1\\n\\n\\n\\n\\n#print(\"allgen in size\")\\n#print(allgeninv)\\n#print(\"\\n\")\\nprint(\"all bins size\")\\nprint(freqsSum)\\nprint(\"\\n\")\\n\\nprint(\"calculate weighted average results\\n\")\\na= alldataframescoverage[0][0] *0\\n#display(a)\\nfor index in range(len(alldataframescoverage)):\\n    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\\n    a= a+ alldataframescoverage[index][0]*alldataframescoverage[index][1]\\na = a/freqsSum\\n#display weighted averaged coverage\\ndisplay(a)\\n\\n\\nb= alldataframesprecision[0][0] *0\\n#display(b)\\nfor index in range(len(alldataframesprecision)):\\n    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\\n    b= b+ alldataframesprecision[index][0]*alldataframesprecision[index][1]\\nb = b/freqsSum\\n#display weighted averaged precision\\ndisplay(b)\\n\\na = a.astype(str)\\nb = b.astype(str)\\n\\nresult_weighted_Average = a+\" | \"+b\\n\\nprint(\"result_weighted_Average:\\n\")\\ndisplay(result_weighted_Average)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\n",
    "# X_train = X_all\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# train CTGAN\n",
    "z_features = get_noise_features(X_train, categorical_features)\n",
    "z_rows = int(0.25 * X_train.shape[0])\n",
    "z = gen_random_noise(shape=(z_rows, z_features))\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "#confidence_level = c\n",
    "gen_lr = 2e-5\n",
    "loss = 'log'\n",
    "\n",
    "#now ctgan synthesizer gets conf levels as input\n",
    "rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n",
    "                            blackbox_model=rf,\n",
    "                            preprocessing_pipeline=preprocessor,\n",
    "                            bb_loss=loss,\n",
    "                            confidence_levels=top_c_lst\n",
    "                            )\n",
    "#print(rf_ctgan.confidence_levels)\n",
    "\n",
    "print(f\"Training CTGAN for c list = {top_c_lst} ...\")\n",
    "#removed conf level from fit input arguements\n",
    "allconf_levels_hist = rf_ctgan.fit(train_data=z,\n",
    "                                   epochs=epochs,\n",
    "                                   gen_lr=gen_lr,\n",
    "                                   verbose=False\n",
    "                                  )\n",
    "\n",
    "#print(\"\\nhistory of all confidence levels:\\n\")\n",
    "#print(allconf_levels_hist)\n",
    "#print(\"\\n\\n\")\n",
    "# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\n",
    "# plot_losses(hist, title=f'{dataset} loss, c = {confidence_level}')\n",
    "# print()\n",
    "\n",
    "#allsamplesInv = 0\n",
    "#allDataFrames = []\n",
    "#allgeninv= 0\n",
    "alldataframescoverage =[]\n",
    "alldataframesprecision =[]\n",
    "freqsCounter = 0\n",
    "#add here conf loop, send each conf to samples as input each loop\n",
    "for c in top_c_lst:\n",
    "    print(\"\\tGenerate samples to same dist...\")\n",
    "    # Generate samples to same dist\n",
    "    samples = 100000\n",
    "    #samples = 200000\n",
    "    gen_data,gen_fakeacts = rf_ctgan.sample(samples,c)\n",
    "    y_prob = rf.predict_proba(gen_data)\n",
    "    print(y_prob)\n",
    "    y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "    #print(y_conf_gen)\n",
    "    #print(y_conf_train)\n",
    "\n",
    "    #train_bucktes_gen = pd.value_counts(y_conf_gen, bins=10, sort=False)\n",
    "    #print(train_bucktes_gen)\n",
    "    # ans is the indices of gen_data to make the same dist\n",
    "    ans,train_ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "    gen_data_same_dist = gen_data.iloc[ans]\n",
    "    y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\n",
    "    #take only relevant sample from train\n",
    "    relevant_train_data = X_train_pd.iloc[train_ans]\n",
    "    relevant_y_conf_train = y_conf_train[train_ans]\n",
    "\n",
    "\n",
    "\n",
    "    # inverse the generated data\n",
    "    scaler = get_scaler(preprocessor)\n",
    "    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "    gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "\n",
    "    #calc all inv\n",
    "    #freqs[freqsCounter] probably in our the gen size data train\n",
    "    # in the interval bin that c in it\n",
    "    #allgeninv = allgeninv + freqs[freqsCounter]\n",
    "    #calc end\n",
    "\n",
    "    # y_conf_gen_same_dist, gen_data_inv what we want\n",
    "    # results\n",
    "    # E. Calculate coverage for each similarity and conf diff thresholds\n",
    "\n",
    "    #sum all geninvsamples\n",
    "    #allsamplesInv =allsamplesInv + gen_data_inv.size()\n",
    "\n",
    "    print(\"gen_data\")\n",
    "    print(gen_data_inv.shape)\n",
    "    print(\"relevant_X_train\")\n",
    "    print(relevant_train_data.shape)\n",
    "    print(\"y_conf_gen\")\n",
    "    print(y_conf_gen_same_dist.shape)\n",
    "    print(\"relevant_y_conf_train\")\n",
    "    print(relevant_y_conf_train.shape)\n",
    "\n",
    "\n",
    "    print(f\"\\tWorking on results...\")\n",
    "    results,coverage, precision = table(gen_data_inv, relevant_train_data, y_conf_gen_same_dist, relevant_y_conf_train)\n",
    "\n",
    "    print(\"datagen inv size:\")\n",
    "    print(gen_data_inv.size)\n",
    "    print(\"\\n\")\n",
    "    print(\"current bin size:\")\n",
    "    print(freqs[freqsCounter])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #keep all data frames\n",
    "    alldataframescoverage.append([coverage,freqs[freqsCounter]])\n",
    "    alldataframesprecision.append([precision,freqs[freqsCounter]])\n",
    "   # allDataFrames.append(results)\n",
    "\n",
    "    print(f\"\\tResults for confidence level = {c}\")\n",
    "    display(results)\n",
    "    freqsCounter=freqsCounter+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(\"allgen in size\")\n",
    "#print(allgeninv)\n",
    "#print(\"\\n\")\n",
    "print(\"all bins size\")\n",
    "print(freqsSum)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"calculate weighted average results\\n\")\n",
    "a= alldataframescoverage[0][0] *0\n",
    "#display(a)\n",
    "for index in range(len(alldataframescoverage)):\n",
    "    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\n",
    "    a= a+ alldataframescoverage[index][0]*alldataframescoverage[index][1]\n",
    "a = a/freqsSum\n",
    "#display weighted averaged coverage\n",
    "display(a)\n",
    "\n",
    "\n",
    "b= alldataframesprecision[0][0] *0\n",
    "#display(b)\n",
    "for index in range(len(alldataframesprecision)):\n",
    "    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\n",
    "    b= b+ alldataframesprecision[index][0]*alldataframesprecision[index][1]\n",
    "b = b/freqsSum\n",
    "#display weighted averaged precision\n",
    "display(b)\n",
    "\n",
    "a = a.astype(str)\n",
    "b = b.astype(str)\n",
    "\n",
    "result_weighted_Average = a+\" | \"+b\n",
    "\n",
    "print(\"result_weighted_Average:\\n\")\n",
    "display(result_weighted_Average)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf_train_data\n",
      "\n",
      "y_conf_test_data\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5cb28d44b485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#now ctgan synthesizer gets conf levels as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n\u001b[0m\u001b[0;32m     45\u001b[0m                             \u001b[0mblackbox_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                             \u001b[0mpreprocessing_pipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\git_CTGAN_project_directory\\CTGAN\\ctgan\\synthesizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, embedding_dim, gen_dim, dis_dim, l2scale, batch_size, discriminator_steps, log_frequency, blackbox_model, preprocessing_pipeline, bb_loss, confidence_levels)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_frequency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrained_epoches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\roi52\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mis_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# This function never throws and returns 0 if driver is missing or can't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# be initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDeviceCount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import xlsxwriter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#create excel file\n",
    "workbook = xlsxwriter.Workbook('German_confidences.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#keeps train and test seperatly\n",
    "#clf.fit(X_train_data, y_train_data)\n",
    "#y_prob_train_data = rf.predict_proba(X_train_data)\n",
    "y_conf_train_data = y_conf_train  # confidence scores\n",
    "print(\"y_conf_train_data\\n\")\n",
    "\n",
    "#clf.fit(X_test_data, y_test_data)\n",
    "y_prob_test_data = rf.predict_proba(X_test_data)\n",
    "y_conf_test_data = y_prob_test_data[:, 0]  # confidence scores\n",
    "print(\"y_conf_test_data\\n\")\n",
    "#print(y_conf_train)\n",
    "#keeped\n",
    "\n",
    "\n",
    "\n",
    "# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\n",
    "# X_train = X_all\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# train CTGAN\n",
    "z_features = get_noise_features(X_train, categorical_features)\n",
    "z_rows = int(0.25 * X_train.shape[0])\n",
    "z = gen_random_noise(shape=(z_rows, z_features))\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "#confidence_level = c\n",
    "gen_lr = 2e-5\n",
    "loss = 'log'\n",
    "\n",
    "#now ctgan synthesizer gets conf levels as input\n",
    "rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n",
    "                            blackbox_model=rf,\n",
    "                            preprocessing_pipeline=preprocessor,\n",
    "                            bb_loss=loss,\n",
    "                            confidence_levels=top_c_lst\n",
    "                            )\n",
    "#print(rf_ctgan.confidence_levels)\n",
    "\n",
    "print(f\"Training CTGAN for c list = {top_c_lst} ...\")\n",
    "#removed conf level from fit input arguements\n",
    "allconf_levels_hist = rf_ctgan.fit(train_data=z,\n",
    "                                   epochs=epochs,\n",
    "                                   gen_lr=gen_lr,\n",
    "                                   verbose=False\n",
    "                                  )\n",
    "\n",
    "#print(\"\\nhistory of all confidence levels:\\n\")\n",
    "#print(allconf_levels_hist)\n",
    "#print(\"\\n\\n\")\n",
    "# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\n",
    "# plot_losses(hist, title=f'{dataset} loss, c = {confidence_level}')\n",
    "# print()\n",
    "\n",
    "#allsamplesInv = 0\n",
    "#allDataFrames = []\n",
    "#allgeninv= 0\n",
    "#alldataframescoverage =[]\n",
    "#alldataframesprecision =[]\n",
    "freqsCounter = 0\n",
    "#add here conf loop, send each conf to samples as input each loop\n",
    "\n",
    "#to delete\n",
    "#c= top_c_lst[0]\n",
    "#top_c_lst = [c]\n",
    "#delete above\n",
    "for c in top_c_lst:\n",
    "    print(\"\\tGenerate samples to same dist...\")\n",
    "    # Generate samples to same dist\n",
    "    samples = 100000\n",
    "    gen_data,gen_fakeacts = rf_ctgan.sample(samples,c)\n",
    "    y_prob = rf.predict_proba(gen_data)\n",
    "    y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "    \n",
    "    print(\"gen data\\n\")\n",
    "    print(gen_data)\n",
    "\n",
    "    # ans is the indices of gen_data to make the same dist\n",
    "    ans,train_ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "    gen_data_same_dist = gen_data.iloc[ans]\n",
    "    y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\n",
    "    # inverse the generated data\n",
    "    scaler = get_scaler(preprocessor)\n",
    "    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "    #gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "\n",
    "    #find kmean to geninv ndarray\n",
    "    kmeans = KMeans(n_clusters=1).fit(gen_data_inv)\n",
    "    gen_data_inv_centroide = kmeans.cluster_centers_\n",
    "\n",
    "    #create new worksheet, excel for bin Contains Conf c\n",
    "    name =\"bin Contains Conf \"+str(c)\n",
    "    worksheet = workbook.add_worksheet(name)\n",
    "\n",
    "    #create columns name of excel worksheet\n",
    "    worksheet.write('A1', 'TR/TS_index')\n",
    "    worksheet.write('B1', 'train/test')\n",
    "    worksheet.write('C1', 'cosin_similarity')\n",
    "\n",
    "    #fill the current worksheet excel\n",
    "    row =1\n",
    "    col = 0\n",
    "    #isTrain= True\n",
    "    #j=0\n",
    "    # Iterate over the data and write it out row by row.\n",
    "    #train_counter = 0\n",
    "    #print(x_train_data[0])\n",
    "    #print(x_train_data[0].shape)\n",
    "    #print(gen_data_inv_centroide)\n",
    "    #print(gen_data_inv_centroide.shape)\n",
    "    for sample_idx, sample_conf in enumerate (y_conf_train_data):\n",
    "        #if the conf of data is in the current interval\n",
    "        #so we want to add it to the excel bin conf\n",
    "        if(idxs.contains(sample_conf)[freqsCounter]):\n",
    "            #print(\"train entered to excel\\n\")\n",
    "            #down i reshaped to make the train data[freqcount]\n",
    "            #to be in 2D as needed(was 1D) and 1 -1 to make it (1,24)\n",
    "            csm = cosine_similarity(gen_data_inv_centroide, X_train_data[sample_idx].reshape(1,-1)).squeeze()\n",
    "            #print(csm)\n",
    "            #print(sample_idx)\n",
    "            #print(row)\n",
    "            #print(col)\n",
    "            worksheet.write(row, col, sample_idx)\n",
    "            worksheet.write(row, col + 1, 'train')\n",
    "            worksheet.write(row, col + 2, csm)\n",
    "           # isTrain = !isTrain\n",
    "            row += 1\n",
    "            #j+=1\n",
    "            #train_counter+=1\n",
    "\n",
    "\n",
    "\n",
    "    col = 0\n",
    "    #isTrain= True\n",
    "    #j=0\n",
    "    # Iterate over the data and write it out row by row.\n",
    "    #test_counter = 0\n",
    "    #print(y_conf_train_data)\n",
    "    #print(y_conf_test_data)\n",
    "\n",
    "    for sample_idx, sample_conf in enumerate (y_conf_test_data):\n",
    "        #print(\"in test loop\\n\")\n",
    "        #if the conf of data is in the current interval bin\n",
    "        #so we want to add it to the excel bin conf\n",
    "        if(idxs.contains(sample_conf)[freqsCounter]):\n",
    "            #print(\"test entered to excel\\n\")\n",
    "            csm = cosine_similarity(gen_data_inv_centroide, X_test_data[sample_idx].reshape(1,-1)).squeeze()\n",
    "            worksheet.write(row, col, sample_idx)\n",
    "            worksheet.write(row, col + 1, 'test')\n",
    "            worksheet.write(row, col + 2, csm)\n",
    "           # isTrain = !isTrain\n",
    "            row += 1\n",
    "            #j+=1\n",
    "            #test_counter+=1\n",
    "\n",
    "\n",
    "\n",
    "    freqsCounter=freqsCounter+1\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "    #calcute and create excel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
