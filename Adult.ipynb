{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2809,
     "status": "ok",
     "timestamp": 1619040342316,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "YCbFJMe9C3wh",
    "outputId": "a01877ff-6ab3-4418-8ca2-cf8c0fb86e54"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install rdt\n",
    "#this lines only needed to run with google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import sys\n",
    "sys.path.append(\"/content/drive/My Drive/CTGAN/CTGAN\")#save the git project in CTGAN directory and the git project name is CTGAN (do not forget)\n",
    "#all of this are saved in google drive of my university account(the directory CTGAN CTGAN is in it)\n",
    "#this lines only needed to run with google colab\n",
    "\"\"\"\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ctgan import CTGANSynthesizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils import *\n",
    "\n",
    "MODELS_PATH = './models'\n",
    "DATA_PATH = './data/'\n",
    "dataset = 'adult'\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1619040347945,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "TAenpEzlC3wo"
   },
   "outputs": [],
   "source": [
    "from ctgan import load_demo\n",
    "data = load_demo()\n",
    "\n",
    "categorical_features = [\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country',\n",
    "]\n",
    "\n",
    "data = data.drop(columns=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1619040350353,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "xxvSu4k3C3wo"
   },
   "outputs": [],
   "source": [
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4356,
     "status": "ok",
     "timestamp": 1619040358957,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "oSsb1py1C3wp",
    "outputId": "8bd17842-d930-4898-938a-a11ea93a6bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.809\n"
     ]
    }
   ],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "categorical_features = []\n",
    "preprocessor = get_preprocessor(X, categorical_features)\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', rf)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "#keep train alone and test alone for create excel file in code\n",
    "#further in the code\n",
    "X_train_data = X_train.to_numpy()\n",
    "#excel code use ndarray while here it DATAFRAME\n",
    "X_test_data = X_test.to_numpy()\n",
    "#excel code use ndarray while here it DATAFRAME\n",
    "y_train_data = y_train\n",
    "y_test_data= y_test\n",
    "# will used it after/before training\n",
    "#print(X_test_data)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1619039945594,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "f5mx2XgsC3wq",
    "outputId": "3182d929-a6ef-4c8c-fe3d-f8595c8b38b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16465</th>\n",
       "      <td>39</td>\n",
       "      <td>188571</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>54</td>\n",
       "      <td>105010</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30273</th>\n",
       "      <td>32</td>\n",
       "      <td>156464</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>45</td>\n",
       "      <td>32172</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>60</td>\n",
       "      <td>146674</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>25</td>\n",
       "      <td>514716</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>32</td>\n",
       "      <td>207668</td>\n",
       "      <td>13</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>27</td>\n",
       "      <td>104457</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>59</td>\n",
       "      <td>268700</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29733</th>\n",
       "      <td>33</td>\n",
       "      <td>59083</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26048 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week\n",
       "16465   39  188571              7             0             0              40\n",
       "5625    54  105010             13             0             0              40\n",
       "30273   32  156464              9             0          1902              50\n",
       "3136    45   32172             10             0             0              50\n",
       "4521    60  146674              6             0             0              40\n",
       "...    ...     ...            ...           ...           ...             ...\n",
       "32511   25  514716             13             0             0              40\n",
       "5192    32  207668             13         15024             0              45\n",
       "12172   27  104457             13             0             0              40\n",
       "235     59  268700              9             0             0              40\n",
       "29733   33   59083             13             0          1902              45\n",
       "\n",
       "[26048 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 1360,
     "status": "ok",
     "timestamp": 1619040365516,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "TT7fboH5C3wq",
    "outputId": "c2a71d24-9b2b-47d5-c03f-f19aec0f9ff4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_prob = clf.predict_proba(X_train)\n",
    "y_conf_train = y_prob[:, 0]  # confidence scores\n",
    "plot_confidence_levels(y_conf_train, \"Confidence scores for X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1619040369483,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "xQ7Wt7ypC3wr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf bucket values:\n",
      "\n",
      "[ 2353  1250  1407  1164   162    62   380  1337  2664 15269]\n",
      "conf bucket sum of vals:\n",
      "\n",
      "26048\n"
     ]
    }
   ],
   "source": [
    "# Create bucket (intervals) from generated data\n",
    "top_c = 10\n",
    "conf_bucktes = pd.value_counts(y_conf_train, bins=10, sort=False)\n",
    "idxs, freqs = conf_bucktes.index, conf_bucktes.values\n",
    "print(\"conf bucket values:\\n\")\n",
    "print(freqs)\n",
    "print(\"conf bucket sum of vals:\\n\")\n",
    "print(freqs.sum())\n",
    "# extract top_c intervals by frequency values\n",
    "intervals_idxs = np.argsort(freqs)[::-1][:top_c]\n",
    "top_c_intervals = idxs[intervals_idxs]\n",
    "\n",
    "# create top_c_lst as the middle of the interval\n",
    "top_c_lst = [(interval.right + interval.left)/2 for interval in top_c_intervals]\n",
    "top_c_lst = sorted(round(x, 4) for x in top_c_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1619040373939,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "8NHoxJwYC3wr",
    "outputId": "353f4bc1-e2f3-4234-920f-db0107210638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.049, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_c_lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67524,
     "status": "ok",
     "timestamp": 1619040530735,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "ENFBtpuJC3wr",
    "outputId": "bfda20dc-543c-4bb3-dd70-dafb6fb6027b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\\n# X_train = X_all \\nX_train_pd = pd.DataFrame(X_train)\\nc = top_c_lst[8]\\n    \\n# train CTGAN\\nz_features = get_noise_features(X_train, categorical_features)\\nz_rows = int(0.25 * X_train.shape[0])\\nz = gen_random_noise(shape=(z_rows, z_features))\\n\\nbatch_size = 50\\nepochs = 5\\nconfidence_level = c\\ngen_lr = 2e-5\\nloss = \\'log\\'\\n\\n\\nrf_ctgan = CTGANSynthesizer(batch_size=batch_size,\\n                            blackbox_model=rf,\\n                            preprocessing_pipeline=preprocessor,\\n                            bb_loss=loss,\\n                            confidence_levels=top_c_lst\\n                            )\\n\\nprint(f\"Training CTGAN for c = {c}...\")\\nallconf_levels_hist = rf_ctgan.fit(train_data=z,\\n                    epochs=epochs,\\n                    gen_lr=gen_lr,\\n                    verbose=False\\n                    )\\n\\n# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\\n# plot_losses(hist, title=f\\'{dataset} loss, c = {confidence_level}\\')\\n# print()\\n\\n\\nprint(\"\\tGenerate samples to same dist...\")\\n# Generate samples to same dist\\nsamples = 100000\\ngen_data = rf_ctgan.sample(samples,c)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\n",
    "# X_train = X_all \n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "c = top_c_lst[8]\n",
    "    \n",
    "# train CTGAN\n",
    "z_features = get_noise_features(X_train, categorical_features)\n",
    "z_rows = int(0.25 * X_train.shape[0])\n",
    "z = gen_random_noise(shape=(z_rows, z_features))\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 5\n",
    "confidence_level = c\n",
    "gen_lr = 2e-5\n",
    "loss = 'log'\n",
    "\n",
    "\n",
    "rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n",
    "                            blackbox_model=rf,\n",
    "                            preprocessing_pipeline=preprocessor,\n",
    "                            bb_loss=loss,\n",
    "                            confidence_levels=top_c_lst\n",
    "                            )\n",
    "\n",
    "print(f\"Training CTGAN for c = {c}...\")\n",
    "allconf_levels_hist = rf_ctgan.fit(train_data=z,\n",
    "                    epochs=epochs,\n",
    "                    gen_lr=gen_lr,\n",
    "                    verbose=False\n",
    "                    )\n",
    "\n",
    "# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\n",
    "# plot_losses(hist, title=f'{dataset} loss, c = {confidence_level}')\n",
    "# print()\n",
    "\n",
    "\n",
    "print(\"\\tGenerate samples to same dist...\")\n",
    "# Generate samples to same dist\n",
    "samples = 100000\n",
    "gen_data = rf_ctgan.sample(samples,c)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L43q2WYBb92y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nallgeninv= 0\\nalldataframescoverage =[]\\nalldataframesprecision =[]\\n#add here conf loop, send each conf to samples as input each loop\\nfor c in top_c_lst:\\n    print(\"\\tGenerate samples to same dist...\")\\n    # Generate samples to same dist\\n    samples = 100000\\n    gen_data = rf_ctgan.sample(samples,c)\\n    y_prob = rf.predict_proba(gen_data)\\n    y_conf_gen = y_prob[:, 0]  # confidence scores\\n\\n\\n    # ans is the indices of gen_data to make the same dist\\n    ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\\n    gen_data_same_dist = gen_data.iloc[ans]\\n    y_conf_gen_same_dist = y_conf_gen[ans]\\n\\n    # inverse the generated data\\n    scaler = get_scaler(preprocessor)\\n    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\\n    gen_data_inv = pd.DataFrame(gen_data_inv)\\n    \\n    #calc all inv\\n    \\n    allgeninv = allgeninv + gen_data_inv.size\\n    #calc end\\n\\n    # y_conf_gen_same_dist, gen_data_inv what we want\\n    # results\\n    # E. Calculate coverage for each similarity and conf diff thresholds\\n\\n    #sum all geninvsamples\\n    #allsamplesInv =allsamplesInv + gen_data_inv.size()\\n\\n    print(f\"\\tWorking on results...\")\\n    results,coverage, precision = table(gen_data_inv, X_train_pd, y_conf_gen_same_dist, y_conf_train)\\n    \\n    print(\"datagen inv size:\")\\n    print(gen_data_inv.size)\\n    print(\"\\n\")\\n    \\n    #keep all data frames\\n    alldataframescoverage.append([coverage,gen_data_inv.size])\\n    alldataframesprecision.append([precision,gen_data_inv.size])\\n   # allDataFrames.append(results)\\n\\n    print(f\"\\tResults for confidence level = {c}\")\\n    display(results)\\n    \\n    \\n    \\n\\nprint(\"allgen in size\")\\nprint(allgeninv)\\nprint(\"\\n\")\\nprint(\"calculate weighted average results\\n\")\\na= alldataframescoverage[0][0] *0\\n#display(a)\\nfor index in range(len(alldataframescoverage)):\\n    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\\n    a= a+ alldataframescoverage[index][0]*alldataframescoverage[index][1]\\na = a/allgeninv\\n#display weighted averaged coverage\\nprint(\"display weighted averaged coverage\\n\")\\ndisplay(a) \\n\\n\\nb= alldataframesprecision[0][0] *0\\n#display(b)\\nfor index in range(len(alldataframesprecision)):\\n    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\\n    b= b+ alldataframesprecision[index][0]*alldataframesprecision[index][1]\\nb = b/allgeninv\\n#display weighted averaged precision\\nprint(\"display weighted averaged precision\\n\")\\ndisplay(b) \\n\\na = a.astype(str)\\nb = b.astype(str)\\n\\nresult_weighted_Average = a+\" | \"+b\\n\\nprint(\"result_weighted_Average:\\n\")\\ndisplay(result_weighted_Average)\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "allgeninv= 0\n",
    "alldataframescoverage =[]\n",
    "alldataframesprecision =[]\n",
    "#add here conf loop, send each conf to samples as input each loop\n",
    "for c in top_c_lst:\n",
    "    print(\"\\tGenerate samples to same dist...\")\n",
    "    # Generate samples to same dist\n",
    "    samples = 100000\n",
    "    gen_data = rf_ctgan.sample(samples,c)\n",
    "    y_prob = rf.predict_proba(gen_data)\n",
    "    y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "\n",
    "\n",
    "    # ans is the indices of gen_data to make the same dist\n",
    "    ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "    gen_data_same_dist = gen_data.iloc[ans]\n",
    "    y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\n",
    "    # inverse the generated data\n",
    "    scaler = get_scaler(preprocessor)\n",
    "    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "    gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "    \n",
    "    #calc all inv\n",
    "    \n",
    "    allgeninv = allgeninv + gen_data_inv.size\n",
    "    #calc end\n",
    "\n",
    "    # y_conf_gen_same_dist, gen_data_inv what we want\n",
    "    # results\n",
    "    # E. Calculate coverage for each similarity and conf diff thresholds\n",
    "\n",
    "    #sum all geninvsamples\n",
    "    #allsamplesInv =allsamplesInv + gen_data_inv.size()\n",
    "\n",
    "    print(f\"\\tWorking on results...\")\n",
    "    results,coverage, precision = table(gen_data_inv, X_train_pd, y_conf_gen_same_dist, y_conf_train)\n",
    "    \n",
    "    print(\"datagen inv size:\")\n",
    "    print(gen_data_inv.size)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #keep all data frames\n",
    "    alldataframescoverage.append([coverage,gen_data_inv.size])\n",
    "    alldataframesprecision.append([precision,gen_data_inv.size])\n",
    "   # allDataFrames.append(results)\n",
    "\n",
    "    print(f\"\\tResults for confidence level = {c}\")\n",
    "    display(results)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"allgen in size\")\n",
    "print(allgeninv)\n",
    "print(\"\\n\")\n",
    "print(\"calculate weighted average results\\n\")\n",
    "a= alldataframescoverage[0][0] *0\n",
    "#display(a)\n",
    "for index in range(len(alldataframescoverage)):\n",
    "    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\n",
    "    a= a+ alldataframescoverage[index][0]*alldataframescoverage[index][1]\n",
    "a = a/allgeninv\n",
    "#display weighted averaged coverage\n",
    "print(\"display weighted averaged coverage\\n\")\n",
    "display(a) \n",
    "\n",
    "\n",
    "b= alldataframesprecision[0][0] *0\n",
    "#display(b)\n",
    "for index in range(len(alldataframesprecision)):\n",
    "    #func = lambda s1, s2: s1 + s2*alldataframes[index][1]\n",
    "    b= b+ alldataframesprecision[index][0]*alldataframesprecision[index][1]\n",
    "b = b/allgeninv\n",
    "#display weighted averaged precision\n",
    "print(\"display weighted averaged precision\\n\")\n",
    "display(b) \n",
    "\n",
    "a = a.astype(str)\n",
    "b = b.astype(str)\n",
    "\n",
    "result_weighted_Average = a+\" | \"+b\n",
    "\n",
    "print(\"result_weighted_Average:\\n\")\n",
    "display(result_weighted_Average)\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1619040564589,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "SIl4JnuHC3ws",
    "outputId": "04f13e75-6df4-442d-abe6-0e8167fa7a52"
   },
   "outputs": [],
   "source": [
    "#gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 14308,
     "status": "ok",
     "timestamp": 1619040605335,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "yLXxWvtkC3ws"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_prob = rf.predict_proba(gen_data)\\ny_conf_gen = y_prob[:, 0]  # confidence scores\\n\\n# ans is the indices of gen_data to make the same dist \\nans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\\ngen_data_same_dist = gen_data.iloc[ans]\\ny_conf_gen_same_dist = y_conf_gen[ans]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "y_prob = rf.predict_proba(gen_data)\n",
    "y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "\n",
    "# ans is the indices of gen_data to make the same dist \n",
    "ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "gen_data_same_dist = gen_data.iloc[ans]\n",
    "y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1619040614491,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "bYHxR9x6C3wt",
    "outputId": "4fa58605-4ab3-42df-d5bb-e3563a0781cf"
   },
   "outputs": [],
   "source": [
    "#plot_confidence_levels(y_conf_gen_same_dist, \"Confidence scores for X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1619040622208,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "vmU6-j9eC3wt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# inverse the generated data\\nscaler = get_scaler(preprocessor)\\ngen_data_inv = scaler.inverse_transform(gen_data_same_dist)\\ngen_data_inv = pd.DataFrame(gen_data_inv)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# inverse the generated data\n",
    "scaler = get_scaler(preprocessor)\n",
    "gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "executionInfo": {
     "elapsed": 2492984,
     "status": "ok",
     "timestamp": 1619043116683,
     "user": {
      "displayName": "Roye Katzav",
      "photoUrl": "",
      "userId": "04460651837835716017"
     },
     "user_tz": -180
    },
    "id": "dY0ZOVCCC3wt",
    "outputId": "393a66f0-c718-4cca-c13b-5af463b62e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# y_conf_gen_same_dist, gen_data_inv what we want\\n# results\\n# E. Calculate coverage for each similarity and conf diff thresholds\\nprint(f\"\\tWorking on results...\")\\nresults,coverage, precision = table(gen_data_inv, X_train_pd, y_conf_gen_same_dist, y_conf_train)\\nprint(f\"\\tResults for confidence level = {c}\")\\ndisplay(results)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# y_conf_gen_same_dist, gen_data_inv what we want\n",
    "# results\n",
    "# E. Calculate coverage for each similarity and conf diff thresholds\n",
    "print(f\"\\tWorking on results...\")\n",
    "results,coverage, precision = table(gen_data_inv, X_train_pd, y_conf_gen_same_dist, y_conf_train)\n",
    "print(f\"\\tResults for confidence level = {c}\")\n",
    "display(results)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf_train_data\n",
      "\n",
      "y_conf_test_data\n",
      "\n",
      "Training CTGAN for c list = [0.049, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95] ...\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n",
      "\tGenerate samples to same dist...\n",
      "enter train loop excel\n",
      "\n",
      "enter test loop excel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#create excel file\n",
    "workbook = xlsxwriter.Workbook('Adult_confidences.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#keeps train and test seperatly\n",
    "#clf.fit(X_train_data, y_train_data)\n",
    "#y_prob_train_data = rf.predict_proba(X_train_data)\n",
    "y_conf_train_data = y_conf_train  # confidence scores\n",
    "#we allready trained with trained data above so only need to chenged\n",
    "#its variable to fit it to code below\n",
    "print(\"y_conf_train_data\\n\")\n",
    "\n",
    "#clf.fit(X_test_data, y_test_data)\n",
    "#no need  to train on test\n",
    "y_prob_test_data = rf.predict_proba(X_test_data)\n",
    "y_conf_test_data = y_prob_test_data[:, 0]  # confidence scores\n",
    "print(\"y_conf_test_data\\n\")\n",
    "#print(y_conf_train)\n",
    "#keeped\n",
    "\n",
    "\n",
    "\n",
    "# X_all = np.concatenate([X_train, y_train.reshape(-1,1)], axis=1)\n",
    "# X_train = X_all\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# train CTGAN\n",
    "z_features = get_noise_features(X_train, categorical_features)\n",
    "z_rows = int(0.25 * X_train.shape[0])\n",
    "z = gen_random_noise(shape=(z_rows, z_features))\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "#confidence_level = c\n",
    "gen_lr = 2e-5\n",
    "loss = 'log'\n",
    "\n",
    "#now ctgan synthesizer gets conf levels as input\n",
    "rf_ctgan = CTGANSynthesizer(batch_size=batch_size,\n",
    "                            blackbox_model=rf,\n",
    "                            preprocessing_pipeline=preprocessor,\n",
    "                            bb_loss=loss,\n",
    "                            confidence_levels=top_c_lst\n",
    "                            )\n",
    "#print(rf_ctgan.confidence_levels)\n",
    "\n",
    "print(f\"Training CTGAN for c list = {top_c_lst} ...\")\n",
    "#removed conf level from fit input arguements\n",
    "allconf_levels_hist = rf_ctgan.fit(train_data=z,\n",
    "                                   epochs=epochs,\n",
    "                                   gen_lr=gen_lr,\n",
    "                                   verbose=False\n",
    "                                  )\n",
    "\n",
    "#print(\"\\nhistory of all confidence levels:\\n\")\n",
    "#print(allconf_levels_hist)\n",
    "#print(\"\\n\\n\")\n",
    "# rf_ctgan.save(f\"{MODELS_PATH}/{dataset}_ctgan_c_{confidence_level}.pkl\")\n",
    "# plot_losses(hist, title=f'{dataset} loss, c = {confidence_level}')\n",
    "# print()\n",
    "\n",
    "#allsamplesInv = 0\n",
    "#allDataFrames = []\n",
    "#allgeninv= 0\n",
    "#alldataframescoverage =[]\n",
    "#alldataframesprecision =[]\n",
    "freqsCounter = 0\n",
    "#add here conf loop, send each conf to samples as input each loop\n",
    "\n",
    "#to delete\n",
    "#c= top_c_lst[0]\n",
    "#top_c_lst = [c]\n",
    "#delete above\n",
    "for c in top_c_lst:\n",
    "    print(\"\\tGenerate samples to same dist...\")\n",
    "    # Generate samples to same dist\n",
    "    samples = 100000\n",
    "    gen_data = rf_ctgan.sample(samples,c)\n",
    "    y_prob = rf.predict_proba(gen_data)\n",
    "    y_conf_gen = y_prob[:, 0]  # confidence scores\n",
    "\n",
    "\n",
    "    # ans is the indices of gen_data to make the same dist\n",
    "    ans = gen_data_to_same_conf_dist_as_train(y_conf_gen, y_conf_train)\n",
    "    gen_data_same_dist = gen_data.iloc[ans]\n",
    "    y_conf_gen_same_dist = y_conf_gen[ans]\n",
    "\n",
    "    # inverse the generated data\n",
    "    scaler = get_scaler(preprocessor)\n",
    "    gen_data_inv = scaler.inverse_transform(gen_data_same_dist)\n",
    "    #gen_data_inv = pd.DataFrame(gen_data_inv)\n",
    "\n",
    "    #find kmean to geninv ndarray\n",
    "    kmeans = KMeans(n_clusters=1).fit(gen_data_inv)\n",
    "    gen_data_inv_centroide = kmeans.cluster_centers_\n",
    "\n",
    "    #create new worksheet, excel for bin Contains Conf c\n",
    "    name =\"bin Contains Conf \"+str(c)\n",
    "    worksheet = workbook.add_worksheet(name)\n",
    "\n",
    "    #create columns name of excel worksheet\n",
    "    worksheet.write('A1', 'TR/TS_index')\n",
    "    worksheet.write('B1', 'train/test')\n",
    "    worksheet.write('C1', 'cosin_similarity')\n",
    "\n",
    "    #fill the current worksheet excel\n",
    "    row =1\n",
    "    col = 0\n",
    "    #isTrain= True\n",
    "    #j=0\n",
    "    # Iterate over the data and write it out row by row.\n",
    "    #train_counter = 0\n",
    "    #print(X_train_data[0])\n",
    "    #print(X_train_data[0].shape)\n",
    "    #print(gen_data_inv_centroide)\n",
    "    #print(gen_data_inv_centroide.shape)\n",
    "    print(\"enter train loop excel\\n\");\n",
    "    for sample_idx, sample_conf in enumerate (y_conf_train_data):\n",
    "        #if the conf of data is in the current interval\n",
    "        #so we want to add it to the excel bin conf\n",
    "        if(idxs.contains(sample_conf)[freqsCounter]):\n",
    "            #print(\"train entered to excel\\n\")\n",
    "            #down i reshaped to make the train data[freqcount]\n",
    "            #to be in 2D as needed(was 1D) and 1 -1 to make it (1,24)\n",
    "            csm = cosine_similarity(gen_data_inv_centroide, X_train_data[sample_idx].reshape(1,-1)).squeeze()\n",
    "            #print(csm)\n",
    "            #print(sample_idx)\n",
    "            #print(row)\n",
    "            #print(col)\n",
    "            worksheet.write(row, col, sample_idx)\n",
    "            worksheet.write(row, col + 1, 'train')\n",
    "            worksheet.write(row, col + 2, csm)\n",
    "           # isTrain = !isTrain\n",
    "            row += 1\n",
    "            #j+=1\n",
    "            #train_counter+=1\n",
    "\n",
    "\n",
    "\n",
    "    col = 0\n",
    "    #isTrain= True\n",
    "    #j=0\n",
    "    # Iterate over the data and write it out row by row.\n",
    "    #test_counter = 0\n",
    "    #print(y_conf_train_data)\n",
    "    #print(y_conf_test_data)\n",
    "    print(\"enter test loop excel\\n\");\n",
    "    for sample_idx, sample_conf in enumerate (y_conf_test_data):\n",
    "        #print(\"in test loop\\n\")\n",
    "        #if the conf of data is in the current interval bin\n",
    "        #so we want to add it to the excel bin conf\n",
    "        if(idxs.contains(sample_conf)[freqsCounter]):\n",
    "            #print(\"test entered to excel\\n\")\n",
    "            csm = cosine_similarity(gen_data_inv_centroide, X_test_data[sample_idx].reshape(1,-1)).squeeze()\n",
    "            worksheet.write(row, col, sample_idx)\n",
    "            worksheet.write(row, col + 1, 'test')\n",
    "            worksheet.write(row, col + 2, csm)\n",
    "           # isTrain = !isTrain\n",
    "            row += 1\n",
    "            #j+=1\n",
    "            #test_counter+=1\n",
    "\n",
    "\n",
    "\n",
    "    freqsCounter=freqsCounter+1\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "    #calcute and create excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Adult.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
